{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ALQ_Optimizer.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "9K4ibJnqApBo",
        "Aj1smLM7B1D2",
        "0kxVgREYCxHl",
        "W9MvaR49C37y",
        "4bJmEsxHCCOH"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9K4ibJnqApBo"
      },
      "source": [
        "#ALQ"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ZFIPlgeAoqs"
      },
      "source": [
        "import math\r\n",
        "import random\r\n",
        "import torch\r\n",
        "from torch.optim.optimizer import Optimizer, required\r\n",
        "\r\n",
        "\r\n",
        "class ALQ_optimizer(Optimizer):\r\n",
        "\r\n",
        "    \"\"\"Implement ALQ optimizer.\r\n",
        "    Arguments:\r\n",
        "        params (iterable): iterable of parameters to optimize or dicts defining parameter groups.\r\n",
        "        lr (float, optional): learning rate (default: 1e-3).\r\n",
        "        betas (Tuple[float, float], optional): coefficients used for computing running averages of gradient and its square (default: (0.9, 0.999)).\r\n",
        "        eps (float, optional): term added to the denominator to improve numerical stability (default: 1e-8).\r\n",
        "        weight_decay (float, optional): weight decay (L2 regularization) (default: 0).\r\n",
        "        \r\n",
        "    Reference:\r\n",
        "        Adam optimizer by Pytorch:\r\n",
        "        https://pytorch.org/docs/stable/_modules/torch/optim/adam.html#Adam\r\n",
        "        On the Convergence of Adam and Beyond:\r\n",
        "        https://openreview.net/forum?id=ryQu7f-RZ\r\n",
        "    \"\"\"\r\n",
        "    \r\n",
        "    def __init__(self, params, lr=1e-3, betas=(0.9, 0.999), eps=1e-8, weight_decay=0.):\r\n",
        "        # Check the validity \r\n",
        "        if not 0.0 <= lr:\r\n",
        "            raise ValueError(\"Invalid learning rate: {}\".format(lr))\r\n",
        "        if not 0.0 <= eps:\r\n",
        "            raise ValueError(\"Invalid epsilon value: {}\".format(eps))\r\n",
        "        if not 0.0 <= betas[0] < 1.0:\r\n",
        "            raise ValueError(\"Invalid beta parameter at index 0: {}\".format(betas[0]))\r\n",
        "        if not 0.0 <= betas[1] < 1.0:\r\n",
        "            raise ValueError(\"Invalid beta parameter at index 1: {}\".format(betas[1]))\r\n",
        "        if not 0.0 <= weight_decay:\r\n",
        "            raise ValueError(\"Invalid weight_decay value: {}\".format(weight_decay))\r\n",
        "        defaults = dict(lr=lr, betas=betas, eps=eps, weight_decay=weight_decay)\r\n",
        "        super(ALQ_optimizer, self).__init__(params, defaults)\r\n",
        "        \r\n",
        "    def __setstate__(self, state):\r\n",
        "        super(ALQ_optimizer, self).__setstate__(state)\r\n",
        "           \r\n",
        "    def step(self, params_bin, mode, pruning_rate=None, closure=None):\r\n",
        "        loss = None\r\n",
        "        if closure is not None:\r\n",
        "            loss = closure()\r\n",
        "        \r\n",
        "        for group in self.param_groups:\r\n",
        "            # Check if this is a pruning step\r\n",
        "            if pruning_rate is not None:\r\n",
        "                importance_list = torch.tensor([])\r\n",
        "            \r\n",
        "            for i, (p_bin, p) in enumerate(zip(params_bin, group['params'])):\r\n",
        "                if p.grad is None:\r\n",
        "                    continue\r\n",
        "                \r\n",
        "                # Compute the gradient in both w domain and alpha domain\r\n",
        "                grad = p.grad.data\r\n",
        "                grad_alpha = p_bin.construct_grad_alpha(grad)\r\n",
        "                state = self.state[p]\r\n",
        "                \r\n",
        "                # Initialize the state parameters in both w domain and alpha domain\r\n",
        "                if len(state) == 0:\r\n",
        "                    state['step_alpha'] = 0\r\n",
        "                    state['exp_avg_alpha'] = torch.zeros_like(p_bin.alpha)\r\n",
        "                    state['exp_avg_sq_alpha'] = torch.zeros_like(p_bin.alpha)\r\n",
        "                    state['max_exp_avg_sq_alpha'] = torch.zeros_like(p_bin.alpha)\r\n",
        "                    \r\n",
        "                    state['step'] = 0\r\n",
        "                    state['exp_avg'] = torch.zeros_like(p.data)\r\n",
        "                    state['exp_avg_sq'] = torch.zeros_like(p.data)\r\n",
        "                    state['max_exp_avg_sq'] = torch.zeros_like(p.data)\r\n",
        "\r\n",
        "                if mode == 'coordinate':\r\n",
        "                    # Update the state parameters in w domain\r\n",
        "                    exp_avg, exp_avg_sq = state['exp_avg'], state['exp_avg_sq']\r\n",
        "                    max_exp_avg_sq = state['max_exp_avg_sq']\r\n",
        "                    beta1, beta2 = group['betas']\r\n",
        "                    state['step'] += 1\r\n",
        "                    # Decay the first and second moment running average coefficient\r\n",
        "                    exp_avg.mul_(beta1).add_(1 - beta1, grad)\r\n",
        "                    exp_avg_sq.mul_(beta2).addcmul_(1 - beta2, grad, grad)\r\n",
        "                    # Maintain the maximum of all second moment running avg. till now\r\n",
        "                    torch.max(max_exp_avg_sq, exp_avg_sq, out=max_exp_avg_sq)\r\n",
        "\r\n",
        "                    # Update the state parameters in alpha domain\r\n",
        "                    exp_avg_alpha, exp_avg_sq_alpha = state['exp_avg_alpha'], state['exp_avg_sq_alpha']\r\n",
        "                    max_exp_avg_sq_alpha = state['max_exp_avg_sq_alpha']\r\n",
        "                    state['step_alpha'] += 1\r\n",
        "                    # L2 regularization on coordinates (in alpha domain)\r\n",
        "                    if group['weight_decay'] != 0:\r\n",
        "                        grad_alpha = grad_alpha.add(p_bin.alpha, alpha=group['weight_decay'])\r\n",
        "                    # Decay the first and second moment running average coefficient\r\n",
        "                    exp_avg_alpha.mul_(beta1).add_(1 - beta1, grad_alpha)\r\n",
        "                    exp_avg_sq_alpha.mul_(beta2).addcmul_(1 - beta2, grad_alpha, grad_alpha)\r\n",
        "                    # Maintain the maximum of all second moment running avg. till now\r\n",
        "                    torch.max(max_exp_avg_sq_alpha, exp_avg_sq_alpha, out=max_exp_avg_sq_alpha)\r\n",
        "                    # Use the max. for normalizing running avg. of gradient\r\n",
        "                    denom_alpha = max_exp_avg_sq_alpha.sqrt().add_(group['eps'])\r\n",
        "                    bias_correction1 = 1 - beta1 ** state['step_alpha']\r\n",
        "                    bias_correction2 = 1 - beta2 ** state['step_alpha']\r\n",
        "\r\n",
        "                    # Compute the pseudo gradient and the pseudo diagonal Hessian \r\n",
        "                    pseudo_grad_alpha = (group['lr'] / bias_correction1) * exp_avg_alpha \r\n",
        "                    pseudo_hessian_alpha = denom_alpha.div(math.sqrt(bias_correction2))\r\n",
        "                    \r\n",
        "                    # Check if this is a pruning step\r\n",
        "                    if pruning_rate is not None:\r\n",
        "                        # Compute the integer used to determine the number of selected alpha's in this layer\r\n",
        "                        float_tmp = p_bin.num_bin_filter.item()*pruning_rate[0]\r\n",
        "                        int_tmp = int(float_tmp)\r\n",
        "                        if random.random()<float_tmp-int_tmp:\r\n",
        "                            int_tmp += 1 \r\n",
        "                        # Sort the importance of binary filters (alpha's) in this layer and select Top-k% (int_tmp) unimportant ones\r\n",
        "                        p_bin_importance_list = p_bin.sort_importance_bin_filter(pseudo_grad_alpha, pseudo_hessian_alpha, int_tmp) \r\n",
        "                        importance_list = torch.cat((importance_list,p_bin_importance_list), 0) \r\n",
        "                    else:\r\n",
        "                        # Take one optimization step on coordinates\r\n",
        "                        p_bin.alpha.add_(-pseudo_grad_alpha/pseudo_hessian_alpha)\r\n",
        "                        # Reconstruct the weight tensor from the current quantization\r\n",
        "                        p_bin.update_w_FP()\r\n",
        "                        tmp_p = p.detach()\r\n",
        "                        tmp_p.zero_().add_(p_bin.w_FP.data)\r\n",
        "                                     \r\n",
        "                elif mode == 'basis':\r\n",
        "                    # Update the state parameters in w domain\r\n",
        "                    exp_avg, exp_avg_sq = state['exp_avg'], state['exp_avg_sq']\r\n",
        "                    max_exp_avg_sq = state['max_exp_avg_sq']\r\n",
        "                    beta1, beta2 = group['betas']\r\n",
        "                    state['step'] += 1\r\n",
        "                    # Decay the first and second moment running average coefficient\r\n",
        "                    exp_avg.mul_(beta1).add_(1 - beta1, grad)\r\n",
        "                    exp_avg_sq.mul_(beta2).addcmul_(1 - beta2, grad, grad)\r\n",
        "                    # Maintain the maximum of all second moment running avg. till now\r\n",
        "                    torch.max(max_exp_avg_sq, exp_avg_sq, out=max_exp_avg_sq)\r\n",
        "                    # Use the max. for normalizing running avg. of gradient\r\n",
        "                    denom = max_exp_avg_sq.sqrt().add_(group['eps'])\r\n",
        "                    bias_correction1 = 1 - beta1 ** state['step']\r\n",
        "                    bias_correction2 = 1 - beta2 ** state['step']\r\n",
        "\r\n",
        "                    # Compute the pseudo gradient and the pseudo diagonal Hessian \r\n",
        "                    pseudo_grad = (group['lr'] / bias_correction1) * exp_avg \r\n",
        "                    pseudo_hessian = denom.div(math.sqrt(bias_correction2))\r\n",
        "                    # Take one optimization step on binary bases\r\n",
        "                    p_bin.optimize_bin_basis(pseudo_grad, pseudo_hessian)\r\n",
        "                    # Speed up with an optimization step on coordinates\r\n",
        "                    p_bin.speedup(pseudo_grad, pseudo_hessian)\r\n",
        "                    # Reconstruct the weight tensor from the current quantization\r\n",
        "                    p_bin.update_w_FP()\r\n",
        "                    tmp_p = p.detach()\r\n",
        "                    tmp_p.zero_().add_(p_bin.w_FP.data)\r\n",
        "\r\n",
        "                    # Update the state parameters in alpha domain (approximately)\r\n",
        "                    state['step_alpha'] += 1\r\n",
        "                    state['exp_avg_alpha'] = p_bin.construct_grad_alpha(exp_avg)\r\n",
        "                    state['exp_avg_sq_alpha'] = p_bin.construct_hessian_alpha(exp_avg_sq)\r\n",
        "                    state['max_exp_avg_sq_alpha'] = p_bin.construct_hessian_alpha(max_exp_avg_sq)\r\n",
        "                    \r\n",
        "                elif mode == 'ste':\r\n",
        "                    # Update the state parameters in w domain\r\n",
        "                    exp_avg, exp_avg_sq = state['exp_avg'], state['exp_avg_sq']\r\n",
        "                    max_exp_avg_sq = state['max_exp_avg_sq']\r\n",
        "                    beta1, beta2 = group['betas']\r\n",
        "                    state['step'] += 1\r\n",
        "                    # Decay the first and second moment running average coefficient\r\n",
        "                    exp_avg.mul_(beta1).add_(1 - beta1, grad)\r\n",
        "                    exp_avg_sq.mul_(beta2).addcmul_(1 - beta2, grad, grad)\r\n",
        "                    # Maintain the maximum of all second moment running avg. till now\r\n",
        "                    torch.max(max_exp_avg_sq, exp_avg_sq, out=max_exp_avg_sq)\r\n",
        "                    # Use the max. for normalizing running avg. of gradient\r\n",
        "                    denom = max_exp_avg_sq.sqrt().add_(group['eps'])\r\n",
        "                    bias_correction1 = 1 - beta1 ** state['step']\r\n",
        "                    bias_correction2 = 1 - beta2 ** state['step']\r\n",
        "\r\n",
        "                    # Compute the pseudo gradient and the pseudo diagonal Hessian \r\n",
        "                    pseudo_grad = (group['lr'] / bias_correction1) * exp_avg \r\n",
        "                    pseudo_hessian = denom.div(math.sqrt(bias_correction2))\r\n",
        "                    \r\n",
        "                    # Take one optimization step on binary bases\r\n",
        "                    p_bin.optimize_bin_basis(pseudo_grad, pseudo_hessian)\r\n",
        "                    # Speed up with an optimization step on coordinates\r\n",
        "                    p_bin.speedup(pseudo_grad, pseudo_hessian)\r\n",
        "                    # Update the maintained full precision weights\r\n",
        "                    p_bin.update_w_FP(-pseudo_grad/pseudo_hessian)\r\n",
        "                    # Reconstruct the weight tensor from the current quantization\r\n",
        "                    tmp_p = p.detach()\r\n",
        "                    tmp_p.zero_().add_(p_bin.reconstruct_w())\r\n",
        "\r\n",
        "                    # Update the state parameters in alpha domain (approximately)\r\n",
        "                    state['step_alpha'] += 1\r\n",
        "                    state['exp_avg_alpha'] = p_bin.construct_grad_alpha(exp_avg)\r\n",
        "                    state['exp_avg_sq_alpha'] = p_bin.construct_hessian_alpha(exp_avg_sq)\r\n",
        "                    state['max_exp_avg_sq_alpha'] = p_bin.construct_hessian_alpha(max_exp_avg_sq)\r\n",
        "            \r\n",
        "            # Check if this is a pruning step        \r\n",
        "            if pruning_rate is not None:\r\n",
        "                # Resort the importance of selected binary filters (alpha's) over all layers \r\n",
        "                sorted_ind = torch.argsort(importance_list[:,-1])\r\n",
        "                # Compute the number of pruned alpha's in this iteration\r\n",
        "                # Note that unlike the paper, M_p varies over iterations here, but this does not influence the pruning schedule. \r\n",
        "                M_p = int(sorted_ind.nelement()*pruning_rate[1])\r\n",
        "                # Determine indexes of alpha's to be pruned\r\n",
        "                ind_prune = sorted_ind[:M_p]\r\n",
        "                list_prune = importance_list[ind_prune,:]\r\n",
        "                # Prune alpha's in each layer and reconstruct the weight tensor\r\n",
        "                for i, (p_bin, p) in enumerate(zip(params_bin, group['params'])):\r\n",
        "                    p_bin.prune_alpha((torch.sort(list_prune[list_prune[:,0]==i,1])[0]).to(torch.int64))\r\n",
        "                    p_bin.update_w_FP()\r\n",
        "                    tmp_p = p.detach()\r\n",
        "                    tmp_p.zero_().add_(p_bin.w_FP.data)\r\n",
        "        return loss\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Aj1smLM7B1D2"
      },
      "source": [
        "#BinaryNet\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y4Xvd7oyB970"
      },
      "source": [
        "import torch\r\n",
        "#from myoptimizer import ALQ_optimizer\r\n",
        "\r\n",
        "\r\n",
        "REL_NORM_THRES = 1e-6\r\n",
        "\r\n",
        "\r\n",
        "def construct_bit_table(bit):\r\n",
        "    \"\"\"Construct a look-up-table to store bitwise values of all intergers given a bitwidth.\"\"\"\r\n",
        "    bit_table = -torch.ones((2**bit, bit), dtype=torch.int8)\r\n",
        "    for i in range(1,2**bit):\r\n",
        "        for j in range(bit):\r\n",
        "            if (i & (1<<j)):\r\n",
        "                bit_table[i,j] = 1\r\n",
        "    return bit_table.to('cuda')\r\n",
        "\r\n",
        "\r\n",
        "def binarize(input_t): \r\n",
        "    \"\"\"Binarize input tensor.\"\"\"\r\n",
        "    dim = input_t.nelement()\r\n",
        "    output_t = torch.ones(dim)\r\n",
        "    output_t[input_t<0] = -1\r\n",
        "    return output_t\r\n",
        "\r\n",
        "\r\n",
        "def transform_bin_basis(w_vec, max_dim, rel_norm_thres=REL_NORM_THRES):\r\n",
        "    \"\"\"Transform a full precision weight vector into multi-bit form, i.e. binary bases and coordiantes.\"\"\"\r\n",
        "    # Reshape the coordinates vector in w domain\r\n",
        "    crd_w = w_vec.detach().view(-1,1)\r\n",
        "    # Get the dimensionality in w domain\r\n",
        "    dim_w = crd_w.nelement()\r\n",
        "    # Determine the max number of dimensionality in alpha domain\r\n",
        "    if dim_w <= max_dim:\r\n",
        "        max_dim_alpha = dim_w\r\n",
        "    else:\r\n",
        "        max_dim_alpha = max_dim\r\n",
        "    # Initialize binary basis matrix in alpha domain\r\n",
        "    bin_basis_alpha = torch.zeros((dim_w, max_dim_alpha))\r\n",
        "    # Initialize coordinates vector in alpha domain\r\n",
        "    crd_alpha = torch.zeros(max_dim_alpha) \r\n",
        "    res = crd_w.detach()\r\n",
        "    res_L2Norm_square = torch.sum(torch.pow(res,2))\r\n",
        "    ori_L2Norm_square = torch.sum(torch.pow(crd_w,2))  \r\n",
        "    for i in range(max_dim_alpha):\r\n",
        "        if res_L2Norm_square/ori_L2Norm_square < rel_norm_thres:\r\n",
        "            break\r\n",
        "        new_bin_basis = binarize(res.view(-1))\r\n",
        "        bin_basis_alpha[:,i] = new_bin_basis \r\n",
        "        B_ = bin_basis_alpha[:,:i+1]\r\n",
        "        # Find the optimal coordinates in the space spanned by B_ \r\n",
        "        alpha_ = torch.mm(torch.inverse(torch.mm(torch.t(B_),B_)),torch.mm(torch.t(B_),crd_w)) \r\n",
        "        # Compute the residual (orthogonal to the space spanned by B_)\r\n",
        "        res = crd_w - torch.mm(B_, alpha_)\r\n",
        "        crd_alpha[:i+1] = alpha_.view(-1)\r\n",
        "        res_L2Norm_square = torch.sum(torch.pow(res,2))   \r\n",
        "    ind_neg = crd_alpha < 0\r\n",
        "    crd_alpha[ind_neg] = -crd_alpha[ind_neg]\r\n",
        "    bin_basis_alpha[:,ind_neg] = -bin_basis_alpha[:,ind_neg]\r\n",
        "    # Get the valid indexes \r\n",
        "    ind_valid = crd_alpha != 0\r\n",
        "    # Get the valid dimensionality in alpha domain\r\n",
        "    dim_alpha = torch.sum(ind_valid) \r\n",
        "    sorted_ind = torch.argsort(crd_alpha[ind_valid])\r\n",
        "    if dim_alpha == 0:\r\n",
        "        return [], [], 0\r\n",
        "    else:\r\n",
        "        return bin_basis_alpha[:,ind_valid][:,sorted_ind].to(torch.int8), crd_alpha[ind_valid][sorted_ind], dim_alpha\r\n",
        "\r\n",
        "\r\n",
        "class ConvLayer_bin(object):\r\n",
        "    \"\"\"This class defines the multi-bit form of the weight tensor of a convolutional layer used in ALQ. \r\n",
        "    Arguments:\r\n",
        "        w_ori (float tensor): the 4-dim pretrained weight tensor of a convolutional layer.\r\n",
        "        ind_layer (int): the index of this layer in the network.\r\n",
        "        structure (string): the structure used for grouping the weights in this layer, optional values: 'kernelwise', 'pixelwise', 'channelwise'.\r\n",
        "        max_bit (int): the maximum bitwidth used in initialization.\r\n",
        "    \"\"\"\r\n",
        "    def __init__(self, w_ori, ind_layer, structure, max_bit):\r\n",
        "        # The layer type\r\n",
        "        self.layer_type = 'conv'\r\n",
        "        # The shape of the weight tensor of this layer\r\n",
        "        self.tensor_shape = w_ori.size()\r\n",
        "        # The maintained full precision weight tensor of this layer used in STE\r\n",
        "        self.w_FP = w_ori.clone().to('cuda')\r\n",
        "        # The index of this layer in the network\r\n",
        "        self.ind_layer = ind_layer\r\n",
        "        # The structure used for grouping the weights in this layer\r\n",
        "        self.structure = structure\r\n",
        "        # The maximum bitwidth used in initialization\r\n",
        "        self.max_bit = max_bit\r\n",
        "        # The binary bases, the coordinates, and the mask (only for parallel computing purposes) of each group\r\n",
        "        self.B, self.alpha, self.mask = self.structured_sketch()\r\n",
        "        # The total number of binary filters in this layer, namely the total number of (valid) alpha's\r\n",
        "        self.num_bin_filter = torch.sum(self.mask)\r\n",
        "        # The average bitwidth of this layer\r\n",
        "        self.avg_bit = self.num_bin_filter.float()/(self.mask.size(0)*self.mask.size(1))\r\n",
        "        # The total number of weights of this layer\r\n",
        "        self.num_weight = self.w_FP.nelement()\r\n",
        "        # The used look-up-table for bitwise values\r\n",
        "        self.bit_table = construct_bit_table(self.max_bit)\r\n",
        "        \r\n",
        "    def structured_sketch(self):\r\n",
        "        \"\"\"Initialize the weight tensor using structured sketching. \r\n",
        "        Namely, structure the weights in groupwise, and quantize each group's weights in multi-bit form w.r.t. the reconstruction error.\r\n",
        "        Return the binary bases, the coordinates, and the mask (only for parallel computing purposes) of each group. \r\n",
        "        \"\"\"\r\n",
        "        w_cpu = self.w_FP.to('cpu')\r\n",
        "        if self.structure == 'kernelwise':\r\n",
        "            B = torch.zeros((self.tensor_shape[0],self.tensor_shape[1],self.max_bit,self.tensor_shape[2]*self.tensor_shape[3])).to(torch.int8)\r\n",
        "            alpha = torch.zeros((self.tensor_shape[0],self.tensor_shape[1],self.max_bit,1)).to(torch.float32)\r\n",
        "            mask =  torch.zeros((self.tensor_shape[0],self.tensor_shape[1],self.max_bit,1)).to(torch.bool)\r\n",
        "        elif self.structure == 'pixelwise':\r\n",
        "            B = torch.zeros((self.tensor_shape[0],self.tensor_shape[2]*self.tensor_shape[3],self.max_bit,self.tensor_shape[1])).to(torch.int8)\r\n",
        "            alpha = torch.zeros((self.tensor_shape[0],self.tensor_shape[2]*self.tensor_shape[3],self.max_bit,1)).to(torch.float32)\r\n",
        "            mask =  torch.zeros((self.tensor_shape[0],self.tensor_shape[2]*self.tensor_shape[3],self.max_bit,1)).to(torch.bool)\r\n",
        "        elif self.structure == 'channelwise':\r\n",
        "            B = torch.zeros((self.tensor_shape[0],1,self.max_bit,self.tensor_shape[1]*self.tensor_shape[2]*self.tensor_shape[3])).to(torch.int8)\r\n",
        "            alpha = torch.zeros((self.tensor_shape[0],1,self.max_bit,1)).to(torch.float32)\r\n",
        "            mask =  torch.zeros((self.tensor_shape[0],1,self.max_bit,1)).to(torch.bool)\r\n",
        "        for k in range(self.tensor_shape[0]):\r\n",
        "            if self.structure == 'kernelwise':\r\n",
        "                for q in range(self.tensor_shape[1]):\r\n",
        "                    bin_basis, crd, dim = transform_bin_basis(w_cpu[k,q,:,:].view(-1), self.max_bit)\r\n",
        "                    mask[k,q,:dim,0] = 1\r\n",
        "                    B[k,q,:dim,:] = torch.t(bin_basis)\r\n",
        "                    alpha[k,q,:dim,0] = crd\r\n",
        "            elif self.structure == 'pixelwise':\r\n",
        "                for h in range(self.tensor_shape[2]):\r\n",
        "                    for w in range(self.tensor_shape[3]):\r\n",
        "                        bin_basis, crd, dim = transform_bin_basis(w_cpu[k,:,h,w].view(-1), self.max_bit)\r\n",
        "                        mask[k,h*self.tensor_shape[3]+w,:dim,0] = 1\r\n",
        "                        B[k,h*self.tensor_shape[3]+w,:dim,:] = torch.t(bin_basis)\r\n",
        "                        alpha[k,h*self.tensor_shape[3]+w,:dim,0] = crd\r\n",
        "            if self.structure == 'channelwise':\r\n",
        "                bin_basis, crd, dim = transform_bin_basis(w_cpu[k,:,:,:].view(-1), self.max_bit)\r\n",
        "                mask[k,0,:dim,0] = 1\r\n",
        "                B[k,0,:dim,:] = torch.t(bin_basis)\r\n",
        "                alpha[k,0,:dim,0] = crd\r\n",
        "        return B.to('cuda'), alpha.to('cuda'), mask.to('cuda')\r\n",
        "\r\n",
        "    def reconstruct_w(self):\r\n",
        "        \"\"\"Reconstruct the weight tensor from the current quantization.\r\n",
        "        Return the reconstructed weight tensor of this layer, i.e. \\hat{w}.\r\n",
        "        \"\"\"\r\n",
        "        w_bin = torch.sum(self.B.float()*(self.alpha*self.mask.float()),dim=2)\r\n",
        "        if self.structure == 'kernelwise':\r\n",
        "            return w_bin.reshape(self.tensor_shape)\r\n",
        "        elif self.structure == 'pixelwise':\r\n",
        "            return torch.transpose(w_bin,1,2).reshape(self.tensor_shape)\r\n",
        "        elif self.structure == 'channelwise':\r\n",
        "            return w_bin.reshape(self.tensor_shape)\r\n",
        "\r\n",
        "    def update_w_FP(self, w_FP_new=None):\r\n",
        "        \"\"\"Update the full precision weight tensor.\r\n",
        "        In STE with loss-aware optimization, w_FP is the maintained full precision weight tensor.\r\n",
        "        In ALQ optimization, w_FP is used to store the reconstructed weight tensor from the current quantization. \r\n",
        "        \"\"\"\r\n",
        "        if w_FP_new is not None:\r\n",
        "            self.w_FP.add_(w_FP_new)\r\n",
        "        else:\r\n",
        "            self.w_FP.zero_().add_(self.reconstruct_w())\r\n",
        "\r\n",
        "    def construct_grad_alpha(self, grad_w):\r\n",
        "        \"\"\"Compute and return the gradient (or the first momentum) in alpha domain w.r.t the loss.\r\n",
        "        \"\"\"\r\n",
        "        if self.structure == 'kernelwise':\r\n",
        "            return torch.matmul(self.B.float(), grad_w.reshape((self.tensor_shape[0],self.tensor_shape[1],-1,1)))*self.mask.float()\r\n",
        "        elif self.structure == 'pixelwise':\r\n",
        "            return torch.matmul(self.B.float(), torch.transpose(grad_w.reshape((self.tensor_shape[0],self.tensor_shape[1],-1,1)), 1,2) )*self.mask.float()\r\n",
        "        elif self.structure == 'channelwise':\r\n",
        "            return torch.matmul(self.B.float(), grad_w.reshape((self.tensor_shape[0],1,-1,1)))*self.mask.float()\r\n",
        "\r\n",
        "    def construct_hessian_alpha(self, diag_hessian_w):\r\n",
        "        \"\"\"Compute and return the diagonal Hessian (or the second momentum) in alpha domain w.r.t the loss.\r\n",
        "        \"\"\"\r\n",
        "        if self.structure == 'kernelwise':\r\n",
        "            diag_hessian = torch.matmul(self.B.float()*diag_hessian_w.reshape((self.tensor_shape[0],self.tensor_shape[1],1,-1)), torch.transpose(self.B,2,3).float())\r\n",
        "            return torch.diagonal(diag_hessian,dim1=-2,dim2=-1).unsqueeze(-1)*self.mask.float()\r\n",
        "        elif self.structure == 'pixelwise':\r\n",
        "            diag_hessian = torch.matmul(self.B.float()*torch.transpose(diag_hessian_w.reshape((self.tensor_shape[0],self.tensor_shape[1],1,-1)), 1,3), torch.transpose(self.B,2,3).float())\r\n",
        "            return torch.diagonal(diag_hessian,dim1=-2,dim2=-1).unsqueeze(-1)*self.mask.float()\r\n",
        "        elif self.structure == 'channelwise':\r\n",
        "            diag_hessian = torch.matmul(self.B.float()*diag_hessian_w.reshape((self.tensor_shape[0],1,1,-1)), torch.transpose(self.B,2,3).float())\r\n",
        "            return torch.diagonal(diag_hessian,dim1=-2,dim2=-1).unsqueeze(-1)*self.mask.float()\r\n",
        "\r\n",
        "    def sort_importance_bin_filter(self, grad_alpha, diag_hessian_alpha, num_top):\r\n",
        "        \"\"\"Compute and sort the importance of binary filters (alpha's) in this layer.\r\n",
        "        The importance is defined by the modeled loss increment caused by pruning each individual alpha.\r\n",
        "        Return the selected num_top alpha's with the least importance.\r\n",
        "        \"\"\"\r\n",
        "        delta_loss_prune = -grad_alpha*self.alpha+0.5*torch.pow(self.alpha,2)*diag_hessian_alpha\r\n",
        "        sorted_ind = torch.argsort(delta_loss_prune[self.mask].view(-1))\r\n",
        "        top_importance_list = torch.tensor([[self.ind_layer, sorted_ind[i], delta_loss_prune.view(-1)[sorted_ind[i]]] for i in range(num_top)])  \r\n",
        "        return top_importance_list\r\n",
        "                \r\n",
        "    def prune_alpha(self, ind_prune): \r\n",
        "        \"\"\"Prune the cooresponding alpha's of this layer give the indexes.\r\n",
        "        \"\"\"\r\n",
        "        num_bin_filter_ = torch.sum(self.mask)\r\n",
        "        self.mask.view(-1)[self.mask.view(-1).nonzero().view(-1)[ind_prune]]=0   \r\n",
        "        self.B *= self.mask.char()\r\n",
        "        self.alpha *= self.mask.float()  \r\n",
        "        self.num_bin_filter = torch.sum(self.mask)  \r\n",
        "        self.avg_bit = self.num_bin_filter.float()/(self.mask.size(0)*self.mask.size(1))\r\n",
        "        if num_bin_filter_-self.num_bin_filter != ind_prune.size(0):\r\n",
        "            print('wrong pruning')\r\n",
        "            return False\r\n",
        "        return True\r\n",
        "        \r\n",
        "    def optimize_bin_basis(self, pseudo_grad, pseudo_hessian):\r\n",
        "        \"\"\"Take one optimization step on the binary bases of this layer while fixing coordinates.\r\n",
        "        \"\"\"\r\n",
        "        # Compute the target weight tensor, i.e. the optimal point in w domain according to the quadratic model function \r\n",
        "        target_w = self.w_FP-pseudo_grad/pseudo_hessian\r\n",
        "        if self.structure == 'kernelwise':\r\n",
        "            all_disc_w = torch.matmul(self.bit_table.view((1,1,self.bit_table.size(0),self.bit_table.size(1))).float(),self.alpha)\r\n",
        "            ind_opt = torch.argmin(torch.abs(target_w.view((self.tensor_shape[0],self.tensor_shape[1],1,-1)) - all_disc_w), dim=2)\r\n",
        "            self.B = torch.transpose((self.bit_table[ind_opt.view(-1),:]).view(self.tensor_shape[0],self.tensor_shape[1],self.tensor_shape[2]*self.tensor_shape[3],self.max_bit), 2,3)\r\n",
        "            self.B *= self.mask.char()\r\n",
        "        elif self.structure == 'pixelwise':\r\n",
        "            all_disc_w = torch.matmul(self.bit_table.view((1,1,self.bit_table.size(0),self.bit_table.size(1))).float(),self.alpha)\r\n",
        "            ind_opt = torch.argmin(torch.abs(torch.transpose(target_w.view((self.tensor_shape[0],self.tensor_shape[1],1,-1)), 1,3) - all_disc_w), dim=2)\r\n",
        "            self.B = torch.transpose((self.bit_table[ind_opt.view(-1),:]).view(self.tensor_shape[0],self.tensor_shape[2]*self.tensor_shape[3],self.tensor_shape[1],self.max_bit), 2,3)\r\n",
        "            self.B *= self.mask.char()\r\n",
        "        elif self.structure == 'channelwise':\r\n",
        "            all_disc_w = torch.matmul(self.bit_table.view((1,1,self.bit_table.size(0),self.bit_table.size(1))).float(),self.alpha)\r\n",
        "            ind_opt = torch.argmin(torch.abs(target_w.view((self.tensor_shape[0],1,1,-1)) - all_disc_w), dim=2)\r\n",
        "            self.B = torch.transpose((self.bit_table[ind_opt.view(-1),:]).view(self.tensor_shape[0],1,self.tensor_shape[1]*self.tensor_shape[2]*self.tensor_shape[3],self.max_bit), 2,3)\r\n",
        "            self.B *= self.mask.char()\r\n",
        "        return True\r\n",
        "            \r\n",
        "    def speedup(self, pseudo_grad, pseudo_hessian):\r\n",
        "        \"\"\"Speed up the optimization on binary bases, i.e. take a following optimization step on coordinates while fixing binary bases. \r\n",
        "        \"\"\"\r\n",
        "        revised_grad_w = -pseudo_hessian*self.w_FP+pseudo_grad\r\n",
        "        if self.structure == 'kernelwise':\r\n",
        "            revised_hessian = torch.matmul(self.B.float()*pseudo_hessian.view((self.tensor_shape[0],self.tensor_shape[1],1,-1)),torch.transpose(self.B,2,3).float())\r\n",
        "            revised_hessian += torch.diag_embed(1+1e-6-(self.mask.float().squeeze(-1))) \r\n",
        "            revised_grad = torch.matmul(self.B.float(),revised_grad_w.view((self.tensor_shape[0],self.tensor_shape[1],-1,1)))\r\n",
        "            self.alpha = -torch.matmul(torch.inverse(revised_hessian),revised_grad)\r\n",
        "        elif self.structure == 'pixelwise':\r\n",
        "            revised_hessian = torch.matmul(self.B.float()*torch.transpose(pseudo_hessian.view((self.tensor_shape[0],self.tensor_shape[1],1,-1)),1,3),torch.transpose(self.B,2,3).float())\r\n",
        "            revised_hessian += torch.diag_embed(1+1e-6-(self.mask.float().squeeze(-1)))\r\n",
        "            revised_grad = torch.matmul(self.B.float(),torch.transpose(revised_grad_w.view((self.tensor_shape[0],self.tensor_shape[1],-1,1)),1,2))\r\n",
        "            self.alpha = -torch.matmul(torch.inverse(revised_hessian),revised_grad)\r\n",
        "        elif self.structure == 'channelwise':\r\n",
        "            revised_hessian = torch.matmul(self.B.float()*pseudo_hessian.view((self.tensor_shape[0],1,1,-1)),torch.transpose(self.B,2,3).float())\r\n",
        "            revised_hessian += torch.diag_embed(1+1e-6-(self.mask.float().squeeze(-1))) \r\n",
        "            revised_grad = torch.matmul(self.B.float(),revised_grad_w.view((self.tensor_shape[0],1,-1,1)))\r\n",
        "            self.alpha = -torch.matmul(torch.inverse(revised_hessian),revised_grad)\r\n",
        "        self.alpha *= self.mask.float()\r\n",
        "        ind_neg = self.alpha<0\r\n",
        "        self.alpha[ind_neg] *= -1\r\n",
        "        self.B.contiguous().view(-1,self.B.size(-1))[ind_neg.view(-1),:] *= -1\r\n",
        "        self.num_bin_filter = torch.sum(self.mask)\r\n",
        "        self.avg_bit = self.num_bin_filter.float()/(self.mask.size(0)*self.mask.size(1))\r\n",
        "        return True\r\n",
        " \r\n",
        "    \r\n",
        "class FCLayer_bin(object):\r\n",
        "    \"\"\"This class defines the multi-bit form of the weight tensor of a convolutional layer used in ALQ. \r\n",
        "    Arguments:\r\n",
        "        w_ori (float tensor): the 4-dim pretrained weight tensor of a convolutional layer.\r\n",
        "        ind_layer (int): the index of this layer in the network.\r\n",
        "        structure (string): the structure used for grouping the weights in this layer, optional values: 'subchannelwise'.\r\n",
        "        max_bit (int): the maximum bitwidth used in initialization.\r\n",
        "    \"\"\"\r\n",
        "    def __init__(self, w_ori, ind_layer, structure, num_subchannel, max_bit):\r\n",
        "        # The layer type\r\n",
        "        self.layer_type = 'fc'\r\n",
        "        # The shape of the weight tensor of this layer\r\n",
        "        self.tensor_shape = w_ori.size()\r\n",
        "        # The maintained full precision weight tensor of this layer used in STE\r\n",
        "        self.w_FP = w_ori.clone().to('cuda')\r\n",
        "        # The index of this layer in the network\r\n",
        "        self.ind_layer = ind_layer\r\n",
        "        # The structure used for grouping the weights in this layer\r\n",
        "        self.structure = structure\r\n",
        "        # The maximum bitwidth used in initialization\r\n",
        "        self.max_bit = max_bit\r\n",
        "        # The number of groups in each channel, i.e. the number of subchannels \r\n",
        "        self.num_subchannel = num_subchannel\r\n",
        "        # The number of weights in each subchannel\r\n",
        "        self.num_w_subc = int(self.tensor_shape[1]/self.num_subchannel)\r\n",
        "        # The binary bases, the coordinates, and the mask (only for parallel computing purposes) of each group\r\n",
        "        self.B, self.alpha, self.mask = self.structured_sketch()\r\n",
        "        # The total number of binary filters in this layer, namely the total number of (valid) alpha's\r\n",
        "        self.num_bin_filter = torch.sum(self.mask)\r\n",
        "        # The average bitwidth of this layer\r\n",
        "        self.avg_bit = self.num_bin_filter.float()/(self.mask.size(0)*self.mask.size(1))\r\n",
        "        # The total number of weights of this layer\r\n",
        "        self.num_weight = self.w_FP.nelement()\r\n",
        "        # The used look-up-table for bitwise values\r\n",
        "        self.bit_table = construct_bit_table(self.max_bit)\r\n",
        "        \r\n",
        "    def structured_sketch(self):\r\n",
        "        \"\"\"Initialize the weight tensor using structured sketching. \r\n",
        "        Namely, structure the weights in groupwise, and quantize each group's weights in multi-bit form w.r.t. the reconstruction error.\r\n",
        "        Return the binary bases, the coordinates, and the mask (only for parallel computing purposes) of each group. \r\n",
        "        \"\"\"\r\n",
        "        w_cpu = self.w_FP.to('cpu')\r\n",
        "        B = torch.zeros((self.tensor_shape[0],self.num_subchannel,self.max_bit,self.num_w_subc)).to(torch.int8)\r\n",
        "        alpha = torch.zeros((self.tensor_shape[0],self.num_subchannel,self.max_bit,1)).to(torch.float32)\r\n",
        "        mask =  torch.zeros((self.tensor_shape[0],self.num_subchannel,self.max_bit,1)).to(torch.bool)\r\n",
        "        for k in range(self.tensor_shape[0]):\r\n",
        "            for (q,i) in enumerate(range(0,self.tensor_shape[1],self.num_w_subc)):\r\n",
        "                bin_basis, crd, dim = transform_bin_basis(w_cpu[k,i:i+self.num_w_subc].view(-1), self.max_bit)\r\n",
        "                mask[k,q,:dim,0] = 1\r\n",
        "                B[k,q,:dim,:] = torch.t(bin_basis)\r\n",
        "                alpha[k,q,:dim,0] = crd\r\n",
        "        return B.to('cuda'), alpha.to('cuda'), mask.to('cuda')\r\n",
        "\r\n",
        "    def reconstruct_w(self):\r\n",
        "        \"\"\"Reconstruct the weight tensor from the current quantization.\r\n",
        "        Return the reconstructed weight tensor of this layer, i.e. \\hat{w}.\r\n",
        "        \"\"\"\r\n",
        "        w_bin = torch.sum(self.B.float()*(self.alpha*self.mask.float()),dim=2)\r\n",
        "        return w_bin.reshape(self.tensor_shape)\r\n",
        "    \r\n",
        "    def update_w_FP(self, w_FP_new=None):\r\n",
        "        \"\"\"Update the full precision weight tensor.\r\n",
        "        In STE with loss-aware optimization, w_FP is the maintained full precision weight tensor.\r\n",
        "        In ALQ optimization, w_FP is used to store the reconstructed weight tensor from the current quantization. \r\n",
        "        \"\"\"\r\n",
        "        if w_FP_new is not None:\r\n",
        "            self.w_FP.add_(w_FP_new)\r\n",
        "        else:\r\n",
        "            self.w_FP.zero_().add_(self.reconstruct_w())        \r\n",
        "    \r\n",
        "    def construct_grad_alpha(self, grad_w):\r\n",
        "        \"\"\"Compute and return the gradient (or the first momentum) in alpha domain w.r.t the loss.\r\n",
        "        \"\"\"\r\n",
        "        return torch.matmul(self.B.float(), grad_w.reshape((self.tensor_shape[0],self.num_subchannel,self.num_w_subc,1)))*self.mask.float()\r\n",
        "        \r\n",
        "    def construct_hessian_alpha(self, diag_hessian_w):\r\n",
        "        \"\"\"Compute and return the diagonal Hessian (or the second momentum) in alpha domain w.r.t the loss.\r\n",
        "        \"\"\"\r\n",
        "        diag_hessian_alpha = torch.matmul(self.B.float()*diag_hessian_w.reshape((self.tensor_shape[0],self.num_subchannel,1,self.num_w_subc)), torch.transpose(self.B,2,3).float())\r\n",
        "        return torch.diagonal(diag_hessian_alpha,dim1=-2,dim2=-1).unsqueeze(-1)*self.mask.float()\r\n",
        "        \r\n",
        "    def sort_importance_bin_filter(self, grad_alpha, diag_hessian_alpha, num_top):\r\n",
        "        \"\"\"Compute and sort the importance of binary filters (alpha's) in this layer.\r\n",
        "        The importance is defined by the modeled loss increment caused by pruning each individual alpha.\r\n",
        "        Return the selected num_top alpha's with the least importance.\r\n",
        "        \"\"\"\r\n",
        "        delta_loss_prune = -grad_alpha*self.alpha+0.5*torch.pow(self.alpha,2)*diag_hessian_alpha\r\n",
        "        sorted_ind = torch.argsort(delta_loss_prune[self.mask].view(-1))\r\n",
        "        top_importance_list = torch.tensor([[self.ind_layer, sorted_ind[i], delta_loss_prune.view(-1)[sorted_ind[i]]] for i in range(num_top)])  \r\n",
        "        return top_importance_list\r\n",
        "                   \r\n",
        "    def prune_alpha(self, ind_prune): \r\n",
        "        \"\"\"Prune the cooresponding alpha's of this layer give the indexes.\r\n",
        "        \"\"\"\r\n",
        "        num_bin_filter_ = torch.sum(self.mask)\r\n",
        "        self.mask.view(-1)[self.mask.view(-1).nonzero().view(-1)[ind_prune]]=0   \r\n",
        "        self.B *= self.mask.char()\r\n",
        "        self.alpha *= self.mask.float()   \r\n",
        "        self.num_bin_filter = torch.sum(self.mask) \r\n",
        "        self.avg_bit = self.num_bin_filter.float()/(self.mask.size(0)*self.mask.size(1))\r\n",
        "        if num_bin_filter_-self.num_bin_filter != ind_prune.size(0):\r\n",
        "            print('wrong pruning')\r\n",
        "            return False\r\n",
        "        return True    \r\n",
        "                   \r\n",
        "    def optimize_bin_basis(self, pseudo_grad, pseudo_hessian):\r\n",
        "        \"\"\"Take one optimization step on the binary bases of this layer while fixing coordinates.\r\n",
        "        \"\"\"\r\n",
        "        # Compute the target weight tensor, i.e. the optimal point in w domain according to the quadratic model function \r\n",
        "        target_w = self.w_FP-pseudo_grad/pseudo_hessian\r\n",
        "        all_disc_w = torch.matmul(self.bit_table.view((1,1,self.bit_table.size(0),self.bit_table.size(1))).float(),self.alpha)\r\n",
        "        ind_opt = torch.argmin(torch.abs(target_w.view((self.tensor_shape[0],self.num_subchannel,1,-1)) - all_disc_w), dim=2)\r\n",
        "        self.B = torch.transpose((self.bit_table[ind_opt[:],:]).view(self.tensor_shape[0],self.num_subchannel,self.num_w_subc,self.max_bit), 2,3)\r\n",
        "        self.B *= self.mask.char()\r\n",
        "        return True\r\n",
        "                               \r\n",
        "    def speedup(self, pseudo_grad, pseudo_hessian):\r\n",
        "        \"\"\"Speed up the optimization on binary bases, i.e. take a following optimization step on coordinates while fixing binary bases. \r\n",
        "        \"\"\"\r\n",
        "        revised_grad_w = -pseudo_hessian*self.w_FP+pseudo_grad\r\n",
        "        revised_hessian = torch.matmul(self.B.float()*pseudo_hessian.view((self.tensor_shape[0],self.num_subchannel,1,-1)),torch.transpose(self.B,2,3).float())\r\n",
        "        revised_hessian += torch.diag_embed(1+1e-6-(self.mask.float().squeeze(-1))) \r\n",
        "        revised_grad = torch.matmul(self.B.float(),revised_grad_w.view((self.tensor_shape[0],self.num_subchannel,-1,1)))\r\n",
        "        self.alpha = -torch.matmul(torch.inverse(revised_hessian),revised_grad)\r\n",
        "        self.alpha *= self.mask.float()\r\n",
        "        ind_neg = self.alpha<0\r\n",
        "        self.alpha[ind_neg] *= -1\r\n",
        "        self.B.contiguous().view(-1,self.B.size(-1))[ind_neg.view(-1),:] *= -1\r\n",
        "        self.num_bin_filter = torch.sum(self.mask)\r\n",
        "        self.avg_bit = self.num_bin_filter.float()/(self.mask.size(0)*self.mask.size(1))\r\n",
        "        return True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4bJmEsxHCCOH"
      },
      "source": [
        "#Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nd3oND7HCFjh"
      },
      "source": [
        "import torch\r\n",
        "#from binarynet import ConvLayer_bin, FCLayer_bin\r\n",
        "\r\n",
        "\r\n",
        "TOPK = (1,5)\r\n",
        "\r\n",
        "def accuracy(output, target, correct_sum, topk=(1,)):\r\n",
        "    \"\"\"Compute the accuracy over the k top predictions for the specified values of k.\"\"\"\r\n",
        "    with torch.no_grad():\r\n",
        "        maxk = max(topk)\r\n",
        "        _, pred = output.topk(maxk, 1, True, True)\r\n",
        "        pred = pred.t()\r\n",
        "        #pred = pred.t()\r\n",
        "        y_pred_list=[]\r\n",
        "        for y in pred:\r\n",
        "            y_pred_list.append(y)\r\n",
        "        #print(\"working till here id 1\")\r\n",
        "        correct = pred.eq(target.view(1, -1).expand_as(pred))\r\n",
        "        #print(\"working till here id 2\")\r\n",
        "\r\n",
        "        for (i,k) in enumerate(topk):\r\n",
        "            #print(\"working till here id 3\")\r\n",
        "            correct_sum[i] += (correct[:k].reshape(-1).float().sum(0, keepdim=True)).item()\r\n",
        "        #print(correct_sum)\r\n",
        "        return \r\n",
        "\r\n",
        "\r\n",
        "def get_accuracy(net, train_loader, loss_func):\r\n",
        "    \"\"\"Get the training loss and training accuracy.\"\"\"\r\n",
        "    net.eval()\r\n",
        "    with torch.no_grad():\r\n",
        "        train_loss = 0.\r\n",
        "        num_batches = 0\r\n",
        "        correct_sum = [0. for i in range(len(TOPK))]\r\n",
        "        total = 0\r\n",
        "        for (inputs, labels) in train_loader:               \r\n",
        "            inputs, labels = inputs.cuda(non_blocking=True), labels.cuda(non_blocking=True)\r\n",
        "            outputs = net(inputs)\r\n",
        "            loss = loss_func(outputs, labels)\r\n",
        "            accuracy(outputs, labels, correct_sum, topk=TOPK)\r\n",
        "            total += labels.size(0)\r\n",
        "            train_loss += loss.data.item()\r\n",
        "            num_batches += 1\r\n",
        "        print('training loss: ', train_loss/num_batches)\r\n",
        "        print('training accuracy: ', [ci/total for ci in correct_sum])\r\n",
        "\r\n",
        "\r\n",
        "def train_fullprecision(net, train_loader, loss_func, optimizer, epoch):\r\n",
        "    \"\"\"Train the original full precision network for one epoch.\"\"\"\r\n",
        "    net.train()\r\n",
        "    train_loss = 0.\r\n",
        "    num_batches = 0\r\n",
        "    correct_sum = [0. for i in range(len(TOPK))]\r\n",
        "    total = 0\r\n",
        "    for (inputs, labels) in train_loader:               \r\n",
        "        inputs, labels = inputs.cuda(non_blocking=True), labels.cuda(non_blocking=True)\r\n",
        "        optimizer.zero_grad()    \r\n",
        "        outputs = net(inputs)\r\n",
        "        loss = loss_func(outputs, labels)\r\n",
        "        loss.backward()   \r\n",
        "        optimizer.step()\r\n",
        "        accuracy(outputs, labels, correct_sum, topk=TOPK)\r\n",
        "        total += labels.size(0)\r\n",
        "        train_loss += loss.data.item()\r\n",
        "        num_batches += 1\r\n",
        "    print(\"epoch: \", epoch, \", training loss: \", train_loss/num_batches)            \r\n",
        "    print('training accuracy: ', [ci/total for ci in correct_sum])\r\n",
        "\r\n",
        "\r\n",
        "def train_coordinate(net, train_loader, loss_func, optimizer_w, optimizer_b, parameters_w_bin, epoch):\r\n",
        "    \"\"\"Train the coordinates for one epoch.\"\"\"\r\n",
        "    net.train()\r\n",
        "    train_loss = 0.\r\n",
        "    num_batches = 0\r\n",
        "    correct_sum = [0. for i in range(len(TOPK))]\r\n",
        "    total = 0\r\n",
        "    for (inputs, labels) in train_loader:               \r\n",
        "        inputs, labels = inputs.cuda(non_blocking=True), labels.cuda(non_blocking=True)\r\n",
        "        optimizer_w.zero_grad()\r\n",
        "        optimizer_b.zero_grad()\r\n",
        "        outputs = net(inputs)\r\n",
        "        loss = loss_func(outputs, labels)\r\n",
        "        loss.backward()   \r\n",
        "        optimizer_b.step()\r\n",
        "        optimizer_w.step(parameters_w_bin, 'coordinate')\r\n",
        "        accuracy(outputs, labels, correct_sum, topk=TOPK)\r\n",
        "        total += labels.size(0)\r\n",
        "        train_loss += loss.data.item()\r\n",
        "        num_batches += 1    \r\n",
        "    print(\"epoch: \", epoch, \", training loss: \", train_loss/num_batches) \r\n",
        "    print('training accuracy: ', [ci/total for ci in correct_sum])\r\n",
        " \r\n",
        "  \r\n",
        "def train_basis(net, train_loader, loss_func, optimizer_w, optimizer_b, parameters_w_bin, epoch):\r\n",
        "    \"\"\"Train the binary bases (with speedup) for one epoch.\"\"\"\r\n",
        "    net.train()\r\n",
        "    train_loss = 0.\r\n",
        "    num_batches = 0\r\n",
        "    correct_sum = [0. for i in range(len(TOPK))]\r\n",
        "    total = 0\r\n",
        "    for inputs, labels in train_loader:               \r\n",
        "        inputs, labels = inputs.cuda(non_blocking=True), labels.cuda(non_blocking=True)\r\n",
        "        optimizer_w.zero_grad()\r\n",
        "        optimizer_b.zero_grad()\r\n",
        "        outputs = net(inputs)\r\n",
        "        loss = loss_func(outputs, labels)\r\n",
        "        loss.backward()   \r\n",
        "        optimizer_b.step()\r\n",
        "        optimizer_w.step(parameters_w_bin, 'basis')\r\n",
        "        accuracy(outputs, labels, correct_sum, topk=TOPK)\r\n",
        "        total += labels.size(0)\r\n",
        "        train_loss += loss.data.item()\r\n",
        "        num_batches += 1   \r\n",
        "    print(\"epoch: \", epoch, \", training loss: \", train_loss/num_batches)                \r\n",
        "    print('training accuracy: ', [ci/total for ci in correct_sum])\r\n",
        "\r\n",
        "\r\n",
        "def train_basis_STE(net, train_loader, loss_func, optimizer_w, optimizer_b, parameters_w_bin, epoch):\r\n",
        "    \"\"\"Train the binary bases (with speedup) by STE for one epoch.\"\"\"\r\n",
        "    net.train()\r\n",
        "    train_loss = 0.\r\n",
        "    num_batches = 0\r\n",
        "    correct_sum = [0. for i in range(len(TOPK))]\r\n",
        "    total = 0\r\n",
        "    for (inputs, labels) in train_loader:               \r\n",
        "        inputs, labels = inputs.cuda(non_blocking=True), labels.cuda(non_blocking=True)\r\n",
        "        optimizer_w.zero_grad()\r\n",
        "        optimizer_b.zero_grad()\r\n",
        "        outputs = net(inputs)\r\n",
        "        loss = loss_func(outputs, labels)\r\n",
        "        loss.backward()   \r\n",
        "        optimizer_b.step()\r\n",
        "        optimizer_w.step(parameters_w_bin, 'ste')\r\n",
        "        accuracy(outputs, labels, correct_sum, topk=TOPK)\r\n",
        "        total += labels.size(0)\r\n",
        "        train_loss += loss.data.item()\r\n",
        "        num_batches += 1    \r\n",
        "    print(\"epoch: \", epoch, \", training loss: \", train_loss/num_batches)                \r\n",
        "    print('training accuracy: ', [ci/total for ci in correct_sum])\r\n",
        "\r\n",
        "\r\n",
        "def prune(net, train_loader, loss_func, optimizer_w, optimizer_b, parameters_w_bin, pruning_rate, epoch):\r\n",
        "    \"\"\"Prune alpha for one epoch.\"\"\"\r\n",
        "    net.eval()\r\n",
        "    train_loss = 0.\r\n",
        "    num_batches = 0\r\n",
        "    correct_sum = [0. for i in range(len(TOPK))]\r\n",
        "    total = 0\r\n",
        "    for (inputs, labels) in train_loader:               \r\n",
        "        inputs, labels = inputs.cuda(non_blocking=True), labels.cuda(non_blocking=True)\r\n",
        "        optimizer_w.zero_grad()\r\n",
        "        optimizer_b.zero_grad()\r\n",
        "        outputs = net(inputs)\r\n",
        "        loss = loss_func(outputs, labels)\r\n",
        "        loss.backward()   \r\n",
        "        optimizer_b.step()\r\n",
        "        optimizer_w.step(parameters_w_bin, 'coordinate', pruning_rate)\r\n",
        "        accuracy(outputs, labels, correct_sum, topk=TOPK)\r\n",
        "        train_loss += loss.data.item()\r\n",
        "        num_batches += 1\r\n",
        "        total += labels.size(0)\r\n",
        "    print(\"epoch: \", epoch, \", pruning loss: \", train_loss/num_batches)                \r\n",
        "    print('pruning accuracy: ', [ci/total for ci in correct_sum])\r\n",
        "    num_weight_layer = 0.\r\n",
        "    num_bit_layer = 0.\r\n",
        "    print('currrent number of binary filters per layer: ')\r\n",
        "    for p_w_bin in parameters_w_bin:\r\n",
        "        print(p_w_bin.num_bin_filter)\r\n",
        "    print('currrent average bitwidth per layer: ')\r\n",
        "    for p_w_bin in parameters_w_bin:\r\n",
        "        num_weight_layer += p_w_bin.num_weight\r\n",
        "        num_bit_layer += p_w_bin.avg_bit*p_w_bin.num_weight\r\n",
        "        print(p_w_bin.avg_bit)\r\n",
        "    print('currrent average bitwidth: ', num_bit_layer/num_weight_layer)\r\n",
        "\r\n",
        " \r\n",
        "def initialize(net, train_loader, loss_func, structure, num_subchannel, max_bit):\r\n",
        "    \"\"\"Initialize the weight tensors of all layers to multi-bit form using structured sketching. \r\n",
        "    Return the iterator over all weight parameters, the iterator over all other parameters, and the iterator over the multi-bit forms of all weight parameters.  \r\n",
        "    \"\"\"\r\n",
        "    parameters_w = []\r\n",
        "    parameters_b = []\r\n",
        "    parameters_w_bin = []\r\n",
        "    i = 0\r\n",
        "    for name, param in net.named_parameters():\r\n",
        "        # Only initialize weight tensors to multi-bit form\r\n",
        "        if 'weight' in name and param.dim()>1:\r\n",
        "            parameters_w.append(param)\r\n",
        "            # Initialize fully connected layers (param.dim()==2)\r\n",
        "            if 'fc' in name or 'classifier' in name:\r\n",
        "                parameters_w_bin.append(FCLayer_bin(param.data, len(parameters_w)-1, structure[i], num_subchannel[i], max_bit[i]))  \r\n",
        "                i += 1\r\n",
        "                tmp_param = param.detach()\r\n",
        "                tmp_param.zero_().add_(parameters_w_bin[-1].reconstruct_w())\r\n",
        "            # Initialize convolutional layers (param.dim()==4)\r\n",
        "            else:\r\n",
        "                parameters_w_bin.append(ConvLayer_bin(param.data, len(parameters_w)-1, structure[i], max_bit[i]))    \r\n",
        "                i += 1\r\n",
        "                tmp_param = param.detach()\r\n",
        "                tmp_param.zero_().add_(parameters_w_bin[-1].reconstruct_w())    \r\n",
        "        # Maintain other parameters (e.g. bias, batch normalization) in full precision \r\n",
        "        else:\r\n",
        "            parameters_b.append(param)\r\n",
        "    net.eval()\r\n",
        "    train_loss = 0.\r\n",
        "    num_batches = 0\r\n",
        "    correct_sum = [0. for i in range(len(TOPK))]\r\n",
        "    total = 0\r\n",
        "    for (inputs, labels) in train_loader:               \r\n",
        "        inputs, labels = inputs.cuda(non_blocking=True), labels.cuda(non_blocking=True)\r\n",
        "        outputs = net(inputs)\r\n",
        "        loss = loss_func(outputs, labels)\r\n",
        "        accuracy(outputs, labels, correct_sum, topk=TOPK)\r\n",
        "        total += labels.size(0)\r\n",
        "        train_loss += loss.data.item()\r\n",
        "        num_batches += 1\r\n",
        "    print('train loss: ', train_loss/num_batches)\r\n",
        "    print('train accuracy: ', [ci/total for ci in correct_sum]) \r\n",
        "    num_weight_layer = 0.\r\n",
        "    num_bit_layer = 0.\r\n",
        "    print('currrent binary filter number per layer: ')\r\n",
        "    for p_w_bin in parameters_w_bin:\r\n",
        "        print(p_w_bin.num_bin_filter)\r\n",
        "    print('currrent average bitwidth per layer: ')\r\n",
        "    for p_w_bin in parameters_w_bin:\r\n",
        "        num_weight_layer += p_w_bin.num_weight\r\n",
        "        num_bit_layer += p_w_bin.avg_bit*p_w_bin.num_weight\r\n",
        "        print(p_w_bin.avg_bit)\r\n",
        "    print('currrent average bitwidth: ', num_bit_layer/num_weight_layer)\r\n",
        "    return parameters_w, parameters_b, parameters_w_bin \r\n",
        "      \r\n",
        "     \r\n",
        "def validate(net, val_loader, loss_func):\r\n",
        "    \"\"\"Get the validation loss and validation accuracy.\"\"\"\r\n",
        "    net.eval()\r\n",
        "    val_loss = 0.\r\n",
        "    num_batches = 0\r\n",
        "    correct_sum = [0. for i in range(len(TOPK))]\r\n",
        "    total = 0\r\n",
        "    with torch.no_grad():\r\n",
        "        for (inputs, labels) in val_loader:\r\n",
        "            inputs, labels = inputs.cuda(non_blocking=True), labels.cuda(non_blocking=True)\r\n",
        "            outputs = net(inputs)\r\n",
        "            loss = loss_func(outputs, labels)  \r\n",
        "            accuracy(outputs, labels, correct_sum, topk=TOPK)\r\n",
        "            total += labels.size(0)\r\n",
        "            val_loss += loss.data.item()\r\n",
        "            num_batches += 1 \r\n",
        "        print('validation loss: ', val_loss/num_batches)\r\n",
        "        print(\"validation accuracy: \", [ci/total for ci in correct_sum])\r\n",
        "        return [ci/total for ci in correct_sum]\r\n",
        "\r\n",
        "\r\n",
        "def test(net, test_loader, loss_func):\r\n",
        "    \"\"\"Get the test loss and test accuracy.\"\"\"\r\n",
        "    net.eval()\r\n",
        "    test_loss = 0.\r\n",
        "    num_batches = 0\r\n",
        "    correct_sum = [0. for i in range(len(TOPK))]\r\n",
        "    total = 0\r\n",
        "    with torch.no_grad():\r\n",
        "        for (inputs, labels) in test_loader:\r\n",
        "            inputs, labels = inputs.cuda(non_blocking=True), labels.cuda(non_blocking=True)\r\n",
        "            outputs = net(inputs)\r\n",
        "            loss = loss_func(outputs, labels)  \r\n",
        "            accuracy(outputs, labels, correct_sum, topk=TOPK)\r\n",
        "            total += labels.size(0)\r\n",
        "            test_loss += loss.data.item()\r\n",
        "            num_batches += 1\r\n",
        "        print(\"test loss: \", test_loss/num_batches)\r\n",
        "        print(\"test accuracy: \", [ci/total for ci in correct_sum])\r\n",
        "        \r\n",
        "\r\n",
        "def save_model(file_name, net, optimizer_w, optimizer_b, parameters_w_bin):\r\n",
        "    \"\"\"Save the state dictionary of model and optimizers.\"\"\"\r\n",
        "    print('saving...')   \r\n",
        "    torch.save({\r\n",
        "        'net_state_dict': net.state_dict(),\r\n",
        "        'optimizer_w_state_dict': optimizer_w.state_dict(),\r\n",
        "        'optimizer_b_state_dict': optimizer_b.state_dict(),\r\n",
        "        'parameters_w_bin': parameters_w_bin,\r\n",
        "        }, file_name)\r\n",
        "\r\n",
        "\r\n",
        "def save_model_ori(file_name, net, optimizer):\r\n",
        "    \"\"\"Save the state dictionary of model and optimizer for full precision training.\"\"\"\r\n",
        "    print('saving...')   \r\n",
        "    torch.save({\r\n",
        "        'net_state_dict': net.state_dict(),\r\n",
        "        'optimizer_state_dict': optimizer.state_dict(),\r\n",
        "        }, file_name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7wqDX8waDG0D"
      },
      "source": [
        "#VGG"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HesKnyKFDY_e"
      },
      "source": [
        "import argparse\r\n",
        "\r\n",
        "import torch\r\n",
        "import math\r\n",
        "from torchvision import datasets, transforms \r\n",
        "\r\n",
        "#from binarynet import ConvLayer_bin, FCLayer_bin\r\n",
        "#from myoptimizer import ALQ_optimizer\r\n",
        "#from train import get_accuracy, train_fullprecision, train_basis, train_basis_STE, train_coordinate, validate, test, prune, initialize, save_model, save_model_ori\r\n",
        "\r\n",
        "\r\n",
        "# Defining the network (VGG_small)  \r\n",
        "class VGG_small(torch.nn.Module):\r\n",
        "    def __init__(self):\r\n",
        "        super(VGG_small, self).__init__()\r\n",
        "        self.features = torch.nn.Sequential(\r\n",
        "            torch.nn.Conv2d(in_channels=3, out_channels=128, kernel_size=3, padding=1),\r\n",
        "            torch.nn.BatchNorm2d(num_features=128, affine=True, momentum=0.1),\r\n",
        "            torch.nn.ReLU(inplace=True),\r\n",
        "            torch.nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=1),\r\n",
        "            torch.nn.MaxPool2d(kernel_size=2, stride=2),\r\n",
        "            torch.nn.BatchNorm2d(num_features=128, affine=True, momentum=0.1),\r\n",
        "            torch.nn.ReLU(inplace=True),\r\n",
        "            torch.nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, padding=1),\r\n",
        "            torch.nn.BatchNorm2d(num_features=256, affine=True, momentum=0.1),\r\n",
        "            torch.nn.ReLU(inplace=True),\r\n",
        "            torch.nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, padding=1),\r\n",
        "            torch.nn.MaxPool2d(kernel_size=2, stride=2),\r\n",
        "            torch.nn.BatchNorm2d(num_features=256, affine=True, momentum=0.1),\r\n",
        "            torch.nn.ReLU(inplace=True),\r\n",
        "            torch.nn.Conv2d(in_channels=256, out_channels=512, kernel_size=3, padding=1),\r\n",
        "            torch.nn.BatchNorm2d(num_features=512, affine=True, momentum=0.1),\r\n",
        "            torch.nn.ReLU(inplace=True),\r\n",
        "            torch.nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, padding=1),\r\n",
        "            torch.nn.MaxPool2d(kernel_size=2, stride=2),\r\n",
        "            torch.nn.BatchNorm2d(num_features=512, affine=True, momentum=0.1),\r\n",
        "            torch.nn.ReLU(inplace=True),\r\n",
        "            )\r\n",
        "        self.classifier = torch.nn.Sequential(\r\n",
        "            torch.nn.Linear(512*4*4, 1024),\r\n",
        "            torch.nn.BatchNorm1d(num_features=1024, affine=True, momentum=0.1),\r\n",
        "            torch.nn.ReLU(inplace=True),\r\n",
        "            torch.nn.Linear(1024, 1024),\r\n",
        "            torch.nn.BatchNorm1d(num_features=1024, affine=True, momentum=0.1),\r\n",
        "            torch.nn.ReLU(inplace=True),\r\n",
        "            torch.nn.Linear(1024, 10),\r\n",
        "        )\r\n",
        "    def forward(self, x):\r\n",
        "        x = self.features(x)\r\n",
        "        x = x.view(x.size(0), -1)\r\n",
        "        x = self.classifier(x)\r\n",
        "        return x\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YXtm4ywVsHCn"
      },
      "source": [
        "**ON CIFAR 10**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GOaV_1ibDH1-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e4c37df6-94e0-4d27-b4de-063c274e41b3"
      },
      "source": [
        "import sys\r\n",
        "sys.argv=['--PRETRAIN','--ALQ','--POSTTRAIN']\r\n",
        "#del sys\r\n",
        "\r\n",
        "if __name__ == \"__main__\":\r\n",
        "\r\n",
        "    parser = argparse.ArgumentParser()\r\n",
        "    parser.add_argument('--data', type=str, default='./data',\r\n",
        "                        help='CIFAR10 dataset directory')\r\n",
        "    parser.add_argument('--val_size', type=int, default=5000,\r\n",
        "                        help='the number of samples in validation dataset')\r\n",
        "    parser.add_argument('--model_ori', type=str, default='./vgg_small_model_ori.pth', \r\n",
        "                        help='the file of the original full precision vgg_small model')\r\n",
        "    parser.add_argument('--model', type=str, default='./vgg_small_model.pth', \r\n",
        "                        help='the file of the quantized vgg_small model')\r\n",
        "    parser.add_argument('--PRETRAIN', action='store_true', \r\n",
        "                        help='train the original full precision vgg_small model')\r\n",
        "    parser.add_argument('--ALQ', action='store_true',  \r\n",
        "                        help='adaptive loss-aware quantize vgg_small model')\r\n",
        "    parser.add_argument('--POSTTRAIN', action='store_true', \r\n",
        "                        help='posttrain the final quantized vgg_small model')\r\n",
        "    parser.add_argument('--lr', type=float, default=1e-3,\r\n",
        "                        help='learning rate')\r\n",
        "    parser.add_argument('--R', type=int, default=1,\r\n",
        "                        help='the number of outer iterations, also the number of pruning')\r\n",
        "    parser.add_argument('--epoch_prune', type=int, default=1,\r\n",
        "                        help='the number of epochs for pruning')\r\n",
        "    parser.add_argument('--epoch_basis', type=int, default=1,\r\n",
        "                        help='the number of epochs for optimizing bases')\r\n",
        "    parser.add_argument('--ld_basis', type=float, default=0.8,\r\n",
        "                        help='learning rate decay factor for optimizing bases')\r\n",
        "    parser.add_argument('--epoch_coord', type=int, default=1,\r\n",
        "                        help='the number of epochs for optimizing coordinates')\r\n",
        "    parser.add_argument('--ld_coord', type=float, default=0.8,\r\n",
        "                        help='learning rate decay factor for optimizing coordinates')\r\n",
        "    parser.add_argument('--wd', type=float, default=0.,\r\n",
        "                        help='weight decay')\r\n",
        "    parser.add_argument('--pr', type=float, default=0.4,\r\n",
        "                        help='the pruning ratio of alpha')\r\n",
        "    parser.add_argument('--top_k', type=float, default=0.002,\r\n",
        "                        help='the ratio of selected alpha in each layer for resorting')\r\n",
        "    parser.add_argument('--structure', type=str, nargs='+', choices=['channelwise', 'kernelwise', 'pixelwise', 'subchannelwise'], \r\n",
        "                        default=['channelwise','pixelwise','pixelwise','pixelwise','pixelwise','pixelwise','subchannelwise','subchannelwise','subchannelwise'],\r\n",
        "                        help='the structure-wise used in each layer')\r\n",
        "    parser.add_argument('--subc', type=int, nargs='+', default=[0,0,0,0,0,0,16,2,2],\r\n",
        "                        help='number of subchannels when using subchannelwise')\r\n",
        "    parser.add_argument('--max_bit', type=int, nargs='+', default=[6,6,6,6,6,6,6,6,6],\r\n",
        "                        help='the maximum bitwidth used in initialization')\r\n",
        "    parser.add_argument('--batch_size', type=int, default=128,\r\n",
        "                        help='the number of training samples in each batch')\r\n",
        "    args = parser.parse_args()\r\n",
        "    \r\n",
        "    torch.backends.cudnn.benchmark = True\r\n",
        "    train_dataset_full = datasets.CIFAR10(args.data, train=True, download=True, transform=transforms.Compose([\r\n",
        "                       \r\n",
        "                        transforms.RandomCrop(32, padding=4),\r\n",
        "                        transforms.RandomHorizontalFlip(),\r\n",
        "                        transforms.ToTensor(),\r\n",
        "                        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\r\n",
        "                        ]))\r\n",
        "                   \r\n",
        "    test_dataset_full = datasets.CIFAR10(args.data, train=False, download=True, transform=transforms.Compose([\r\n",
        "                       \r\n",
        "                        transforms.ToTensor(),\r\n",
        "                        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\r\n",
        "                        ]))\r\n",
        "    val_dataset, train_dataset = torch.utils.data.random_split(train_dataset_full, [args.val_size, len(train_dataset_full)-args.val_size])\r\n",
        "    num_training_sample = len(train_dataset)\r\n",
        "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=args.batch_size, shuffle=True, pin_memory=True, num_workers=8) \r\n",
        "    val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=args.batch_size, shuffle=True, pin_memory=True, num_workers=8)\r\n",
        "    test_loader = torch.utils.data.DataLoader(test_dataset_full, batch_size=args.batch_size, shuffle=True, pin_memory=True, num_workers=8)\r\n",
        "\r\n",
        "\r\n",
        "    \r\n",
        "    print('pretraining...')\r\n",
        "    net = VGG_small().cuda()\r\n",
        "    loss_func = torch.nn.CrossEntropyLoss().cuda()\r\n",
        "        \r\n",
        "    optimizer = torch.optim.Adam(net.parameters(),lr=5e-2)\r\n",
        "    get_accuracy(net, train_loader, loss_func)\r\n",
        "    val_accuracy = validate(net, val_loader, loss_func)\r\n",
        "    best_acc = val_accuracy[0]\r\n",
        "    test(net, test_loader, loss_func)\r\n",
        "    save_model_ori(args.model_ori, net, optimizer)\r\n",
        "        \r\n",
        "    for epoch in range(1):\r\n",
        "            if epoch%30 == 0:\r\n",
        "                optimizer.param_groups[0]['lr'] *= 0.2\r\n",
        "            train_fullprecision(net, train_loader, loss_func, optimizer, epoch)\r\n",
        "            val_accuracy = validate(net, val_loader, loss_func)\r\n",
        "            if val_accuracy[0]>best_acc:\r\n",
        "                best_acc = val_accuracy[0]\r\n",
        "                test(net, test_loader, loss_func)\r\n",
        "                save_model_ori(args.model_ori, net, optimizer) \r\n",
        "        \r\n",
        "    # End of the for loop\r\n",
        "\r\n",
        "    \r\n",
        "    print('adaptive loss-aware quantization...')\r\n",
        "\r\n",
        "    net = VGG_small().cuda()\r\n",
        "    loss_func = torch.nn.CrossEntropyLoss().cuda() \r\n",
        "\r\n",
        "    print('loading pretrained full precision vgg_small model ...')\r\n",
        "    checkpoint = torch.load(args.model_ori)\r\n",
        "    net.load_state_dict(checkpoint['net_state_dict'])\r\n",
        "    for name, param in net.named_parameters():\r\n",
        "            print(name)\r\n",
        "            print(param.size())   \r\n",
        "\r\n",
        "    print('initialization (structured sketching)...')\r\n",
        "    parameters_w, parameters_b, parameters_w_bin = initialize(net, train_loader, loss_func, args.structure, args.subc, args.max_bit)\r\n",
        "    optimizer_b = torch.optim.Adam(parameters_b, weight_decay=args.wd) \r\n",
        "    optimizer_w = ALQ_optimizer(parameters_w, weight_decay=args.wd)\r\n",
        "    val_accuracy = validate(net, val_loader, loss_func)\r\n",
        "    best_acc = val_accuracy[0]\r\n",
        "    test(net, test_loader, loss_func)\r\n",
        "    save_model(args.model, net, optimizer_w, optimizer_b, parameters_w_bin)\r\n",
        "\r\n",
        "    M_p = (args.pr/args.top_k)/(args.epoch_prune*math.ceil(num_training_sample/args.batch_size))\r\n",
        "\r\n",
        "    for r in range(args.R):\r\n",
        "\r\n",
        "            print('outer iteration: ', r)\r\n",
        "            optimizer_b.param_groups[0]['lr'] = args.lr\r\n",
        "            optimizer_w.param_groups[0]['lr'] = args.lr\r\n",
        "            \r\n",
        "            print('optimizing basis...')\r\n",
        "            for q_epoch in range(args.epoch_basis):\r\n",
        "                optimizer_b.param_groups[0]['lr'] *= args.ld_basis\r\n",
        "                optimizer_w.param_groups[0]['lr'] *= args.ld_basis\r\n",
        "                train_basis(net, train_loader, loss_func, optimizer_w, optimizer_b, parameters_w_bin, q_epoch)\r\n",
        "                val_accuracy = validate(net, val_loader, loss_func)\r\n",
        "                if val_accuracy[0]>best_acc:\r\n",
        "                    best_acc = val_accuracy[0]\r\n",
        "                    test(net, test_loader, loss_func)\r\n",
        "                    #save_model(args.model, net, optimizer_w, optimizer_b, parameters_w_bin)\r\n",
        "            \r\n",
        "            print('optimizing coordinates...')\r\n",
        "            for p_epoch in range(args.epoch_coord):\r\n",
        "                optimizer_b.param_groups[0]['lr'] *= args.ld_coord\r\n",
        "                optimizer_w.param_groups[0]['lr'] *= args.ld_coord\r\n",
        "                train_coordinate(net, train_loader, loss_func, optimizer_w, optimizer_b, parameters_w_bin, p_epoch)\r\n",
        "                val_accuracy = validate(net, val_loader, loss_func)\r\n",
        "                if val_accuracy[0]>best_acc:\r\n",
        "                    best_acc = val_accuracy[0]\r\n",
        "                    test(net, test_loader, loss_func)\r\n",
        "                    #save_model(args.model, net, optimizer_w, optimizer_b, parameters_w_bin)\r\n",
        "                    \r\n",
        "            print('pruning...')\r\n",
        "            for t_epoch in range(args.epoch_prune):\r\n",
        "                prune(net, train_loader, loss_func, optimizer_w, optimizer_b, parameters_w_bin, [args.top_k, M_p], t_epoch)\r\n",
        "                val_accuracy = validate(net, val_loader, loss_func)\r\n",
        "                best_acc = val_accuracy[0]\r\n",
        "                test(net, test_loader, loss_func)\r\n",
        "                save_model(args.model, net, optimizer_w, optimizer_b, parameters_w_bin)\r\n",
        "\r\n",
        "\r\n",
        "    \r\n",
        "    print('posttraining...')\r\n",
        "            \r\n",
        "    net = VGG_small().cuda()\r\n",
        "    loss_func = torch.nn.CrossEntropyLoss().cuda()\r\n",
        "\r\n",
        "    parameters_w = []\r\n",
        "    parameters_b = []\r\n",
        "    for name, param in net.named_parameters():\r\n",
        "            if 'weight' in name and param.dim()>1:\r\n",
        "                parameters_w.append(param)\r\n",
        "            else:\r\n",
        "                parameters_b.append(param)\r\n",
        "\r\n",
        "    optimizer_b = torch.optim.Adam(parameters_b, weight_decay=args.wd) \r\n",
        "    optimizer_w = ALQ_optimizer(parameters_w, weight_decay=args.wd)\r\n",
        "        \r\n",
        "    print('load quantized vgg_small model...')\r\n",
        "    checkpoint = torch.load(args.model)\r\n",
        "    net.load_state_dict(checkpoint['net_state_dict'])\r\n",
        "    optimizer_w.load_state_dict(checkpoint['optimizer_w_state_dict'])\r\n",
        "    optimizer_b.load_state_dict(checkpoint['optimizer_b_state_dict'])\r\n",
        "    for state in optimizer_b.state.values():\r\n",
        "            for k, v in state.items():\r\n",
        "                if torch.is_tensor(v):\r\n",
        "                    state[k] = v.cuda()\r\n",
        "    for state in optimizer_w.state.values():\r\n",
        "            for k, v in state.items():\r\n",
        "                if torch.is_tensor(v):\r\n",
        "                    state[k] = v.cuda()\r\n",
        "\r\n",
        "    num_weight_layer = 0.\r\n",
        "    num_bit_layer = 0.\r\n",
        "    print('currrent binary filter number per layer: ')\r\n",
        "    for p_w_bin in parameters_w_bin:\r\n",
        "            print(p_w_bin.num_bin_filter)\r\n",
        "    print('currrent average bitwidth per layer: ')\r\n",
        "    for p_w_bin in parameters_w_bin:\r\n",
        "            num_weight_layer += p_w_bin.num_weight\r\n",
        "            num_bit_layer += p_w_bin.avg_bit*p_w_bin.num_weight\r\n",
        "            print(p_w_bin.avg_bit)\r\n",
        "    print('currrent average bitwidth: ', num_bit_layer/num_weight_layer)\r\n",
        "\r\n",
        "    get_accuracy(net, train_loader, loss_func)\r\n",
        "    val_accuracy = validate(net, val_loader, loss_func)\r\n",
        "    best_acc = val_accuracy[0]\r\n",
        "    test(net, test_loader, loss_func)\r\n",
        "    optimizer_b.param_groups[0]['lr'] = args.lr\r\n",
        "    optimizer_w.param_groups[0]['lr'] = args.lr\r\n",
        "        \r\n",
        "    print('optimizing basis with STE...')\r\n",
        "    for epoch in range(1):\r\n",
        "            optimizer_b.param_groups[0]['lr'] *= 0.95\r\n",
        "            optimizer_w.param_groups[0]['lr'] *= 0.95\r\n",
        "            train_basis_STE(net, train_loader, loss_func, optimizer_w, optimizer_b, parameters_w_bin, epoch)\r\n",
        "            val_accuracy = validate(net, val_loader, loss_func)\r\n",
        "            if val_accuracy[0]>best_acc:\r\n",
        "                best_acc = val_accuracy[0]\r\n",
        "                test(net, test_loader, loss_func)\r\n",
        "                save_model(args.model, net, optimizer_w, optimizer_b, parameters_w_bin)\r\n",
        "        \r\n",
        "    print('optimizing coordinates...')\r\n",
        "    for epoch in range(2):\r\n",
        "            optimizer_b.param_groups[0]['lr'] *= 0.9\r\n",
        "            optimizer_w.param_groups[0]['lr'] *= 0.9\r\n",
        "            train_coordinate(net, train_loader, loss_func, optimizer_w, optimizer_b, parameters_w_bin, epoch)\r\n",
        "            val_accuracy = validate(net, val_loader, loss_func)\r\n",
        "            if val_accuracy[0]>best_acc:\r\n",
        "                best_acc = val_accuracy[0]\r\n",
        "                test(net, test_loader, loss_func)\r\n",
        "                save_model(args.model, net, optimizer_w, optimizer_b, parameters_w_bin)\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "pretraining...\n",
            "training loss:  2.302714389833537\n",
            "training accuracy:  [0.10011111111111111, 0.4992]\n",
            "validation loss:  2.3025242924690246\n",
            "validation accuracy:  [0.099, 0.5072]\n",
            "test loss:  2.3027364573901212\n",
            "test accuracy:  [0.1, 0.5]\n",
            "saving...\n",
            "epoch:  0 , training loss:  1.818170333111828\n",
            "training accuracy:  [0.35755555555555557, 0.8587111111111111]\n",
            "validation loss:  1.4910687416791917\n",
            "validation accuracy:  [0.4854, 0.912]\n",
            "test loss:  1.4532442455050312\n",
            "test accuracy:  [0.4854, 0.9223]\n",
            "saving...\n",
            "adaptive loss-aware quantization...\n",
            "loading pretrained full precision vgg_small model ...\n",
            "features.0.weight\n",
            "torch.Size([128, 3, 3, 3])\n",
            "features.0.bias\n",
            "torch.Size([128])\n",
            "features.1.weight\n",
            "torch.Size([128])\n",
            "features.1.bias\n",
            "torch.Size([128])\n",
            "features.3.weight\n",
            "torch.Size([128, 128, 3, 3])\n",
            "features.3.bias\n",
            "torch.Size([128])\n",
            "features.5.weight\n",
            "torch.Size([128])\n",
            "features.5.bias\n",
            "torch.Size([128])\n",
            "features.7.weight\n",
            "torch.Size([256, 128, 3, 3])\n",
            "features.7.bias\n",
            "torch.Size([256])\n",
            "features.8.weight\n",
            "torch.Size([256])\n",
            "features.8.bias\n",
            "torch.Size([256])\n",
            "features.10.weight\n",
            "torch.Size([256, 256, 3, 3])\n",
            "features.10.bias\n",
            "torch.Size([256])\n",
            "features.12.weight\n",
            "torch.Size([256])\n",
            "features.12.bias\n",
            "torch.Size([256])\n",
            "features.14.weight\n",
            "torch.Size([512, 256, 3, 3])\n",
            "features.14.bias\n",
            "torch.Size([512])\n",
            "features.15.weight\n",
            "torch.Size([512])\n",
            "features.15.bias\n",
            "torch.Size([512])\n",
            "features.17.weight\n",
            "torch.Size([512, 512, 3, 3])\n",
            "features.17.bias\n",
            "torch.Size([512])\n",
            "features.19.weight\n",
            "torch.Size([512])\n",
            "features.19.bias\n",
            "torch.Size([512])\n",
            "classifier.0.weight\n",
            "torch.Size([1024, 8192])\n",
            "classifier.0.bias\n",
            "torch.Size([1024])\n",
            "classifier.1.weight\n",
            "torch.Size([1024])\n",
            "classifier.1.bias\n",
            "torch.Size([1024])\n",
            "classifier.3.weight\n",
            "torch.Size([1024, 1024])\n",
            "classifier.3.bias\n",
            "torch.Size([1024])\n",
            "classifier.4.weight\n",
            "torch.Size([1024])\n",
            "classifier.4.bias\n",
            "torch.Size([1024])\n",
            "classifier.6.weight\n",
            "torch.Size([10, 1024])\n",
            "classifier.6.bias\n",
            "torch.Size([10])\n",
            "initialization (structured sketching)...\n",
            "train loss:  1.4887046278877691\n",
            "train accuracy:  [0.4614888888888889, 0.9173555555555556]\n",
            "currrent binary filter number per layer: \n",
            "tensor(768, device='cuda:0')\n",
            "tensor(6912, device='cuda:0')\n",
            "tensor(13824, device='cuda:0')\n",
            "tensor(13824, device='cuda:0')\n",
            "tensor(27648, device='cuda:0')\n",
            "tensor(27648, device='cuda:0')\n",
            "tensor(98304, device='cuda:0')\n",
            "tensor(12288, device='cuda:0')\n",
            "tensor(120, device='cuda:0')\n",
            "currrent average bitwidth per layer: \n",
            "tensor(6., device='cuda:0')\n",
            "tensor(6., device='cuda:0')\n",
            "tensor(6., device='cuda:0')\n",
            "tensor(6., device='cuda:0')\n",
            "tensor(6., device='cuda:0')\n",
            "tensor(6., device='cuda:0')\n",
            "tensor(6., device='cuda:0')\n",
            "tensor(6., device='cuda:0')\n",
            "tensor(6., device='cuda:0')\n",
            "currrent average bitwidth:  tensor(6., device='cuda:0')\n",
            "validation loss:  1.48384048640728\n",
            "validation accuracy:  [0.4794, 0.9138]\n",
            "test loss:  1.4557887617545793\n",
            "test accuracy:  [0.4753, 0.924]\n",
            "saving...\n",
            "outer iteration:  0\n",
            "optimizing basis...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "--PRETRAIN:131: UserWarning: This overload of add_ is deprecated:\n",
            "\tadd_(Number alpha, Tensor other)\n",
            "Consider using one of the following signatures instead:\n",
            "\tadd_(Tensor other, *, Number alpha) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:882.)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch:  0 , training loss:  1.2342727302827619\n",
            "training accuracy:  [0.5473777777777777, 0.9494888888888889]\n",
            "validation loss:  1.1565889060497283\n",
            "validation accuracy:  [0.5714, 0.9518]\n",
            "test loss:  1.142047124572947\n",
            "test accuracy:  [0.5825, 0.9571]\n",
            "optimizing coordinates...\n",
            "epoch:  0 , training loss:  1.1216780194504694\n",
            "training accuracy:  [0.5911777777777778, 0.9598888888888889]\n",
            "validation loss:  1.0328823938965797\n",
            "validation accuracy:  [0.6204, 0.9674]\n",
            "test loss:  1.000333789783188\n",
            "test accuracy:  [0.6341, 0.967]\n",
            "pruning...\n",
            "epoch:  0 , pruning loss:  0.9933832032098011\n",
            "pruning accuracy:  [0.6419555555555555, 0.9682444444444445]\n",
            "currrent number of binary filters per layer: \n",
            "tensor(765, device='cuda:0')\n",
            "tensor(6663, device='cuda:0')\n",
            "tensor(11697, device='cuda:0')\n",
            "tensor(10944, device='cuda:0')\n",
            "tensor(19762, device='cuda:0')\n",
            "tensor(18916, device='cuda:0')\n",
            "tensor(57010, device='cuda:0')\n",
            "tensor(9198, device='cuda:0')\n",
            "tensor(119, device='cuda:0')\n",
            "currrent average bitwidth per layer: \n",
            "tensor(5.9766, device='cuda:0')\n",
            "tensor(5.7839, device='cuda:0')\n",
            "tensor(5.0768, device='cuda:0')\n",
            "tensor(4.7500, device='cuda:0')\n",
            "tensor(4.2886, device='cuda:0')\n",
            "tensor(4.1050, device='cuda:0')\n",
            "tensor(3.4796, device='cuda:0')\n",
            "tensor(4.4912, device='cuda:0')\n",
            "tensor(5.9500, device='cuda:0')\n",
            "currrent average bitwidth:  tensor(3.8422, device='cuda:0')\n",
            "validation loss:  0.9961504369974137\n",
            "validation accuracy:  [0.6378, 0.9714]\n",
            "test loss:  0.969362541090084\n",
            "test accuracy:  [0.6492, 0.9696]\n",
            "saving...\n",
            "posttraining...\n",
            "load quantized vgg_small model...\n",
            "currrent binary filter number per layer: \n",
            "tensor(765, device='cuda:0')\n",
            "tensor(6663, device='cuda:0')\n",
            "tensor(11697, device='cuda:0')\n",
            "tensor(10944, device='cuda:0')\n",
            "tensor(19762, device='cuda:0')\n",
            "tensor(18916, device='cuda:0')\n",
            "tensor(57010, device='cuda:0')\n",
            "tensor(9198, device='cuda:0')\n",
            "tensor(119, device='cuda:0')\n",
            "currrent average bitwidth per layer: \n",
            "tensor(5.9766, device='cuda:0')\n",
            "tensor(5.7839, device='cuda:0')\n",
            "tensor(5.0768, device='cuda:0')\n",
            "tensor(4.7500, device='cuda:0')\n",
            "tensor(4.2886, device='cuda:0')\n",
            "tensor(4.1050, device='cuda:0')\n",
            "tensor(3.4796, device='cuda:0')\n",
            "tensor(4.4912, device='cuda:0')\n",
            "tensor(5.9500, device='cuda:0')\n",
            "currrent average bitwidth:  tensor(3.8422, device='cuda:0')\n",
            "training loss:  0.989514440975406\n",
            "training accuracy:  [0.6422666666666667, 0.9673777777777778]\n",
            "validation loss:  1.0050322994589806\n",
            "validation accuracy:  [0.6392, 0.964]\n",
            "test loss:  0.9710803922218613\n",
            "test accuracy:  [0.6492, 0.9696]\n",
            "optimizing basis with STE...\n",
            "epoch:  0 , training loss:  0.9821278999813579\n",
            "training accuracy:  [0.6476888888888889, 0.9693555555555555]\n",
            "validation loss:  0.8815664678812027\n",
            "validation accuracy:  [0.6878, 0.9766]\n",
            "test loss:  0.8754823690728296\n",
            "test accuracy:  [0.6873, 0.9786]\n",
            "saving...\n",
            "optimizing coordinates...\n",
            "epoch:  0 , training loss:  0.8088293646208264\n",
            "training accuracy:  [0.7090666666666666, 0.9800888888888889]\n",
            "validation loss:  0.7904245737940073\n",
            "validation accuracy:  [0.717, 0.981]\n",
            "test loss:  0.7870219629022139\n",
            "test accuracy:  [0.7246, 0.9826]\n",
            "saving...\n",
            "epoch:  1 , training loss:  0.7321572665294463\n",
            "training accuracy:  [0.7376888888888888, 0.9838666666666667]\n",
            "validation loss:  0.7646094307303428\n",
            "validation accuracy:  [0.7328, 0.9836]\n",
            "test loss:  0.7355315006231959\n",
            "test accuracy:  [0.7422, 0.9848]\n",
            "saving...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3A3NQtv301zz"
      },
      "source": [
        "copy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z9SomER2E-8K",
        "outputId": "e127a4e9-5c9c-4226-8aa8-5b50e4afd7dc"
      },
      "source": [
        "import sys\r\n",
        "sys.argv=['--PRETRAIN','--ALQ','--POSTTRAIN']\r\n",
        "#del sys\r\n",
        "\r\n",
        "if __name__ == \"__main__\":\r\n",
        "\r\n",
        "    parser = argparse.ArgumentParser()\r\n",
        "    parser.add_argument('--data', type=str, default='./data',\r\n",
        "                        help='CIFAR10 dataset directory')\r\n",
        "    parser.add_argument('--val_size', type=int, default=5000,\r\n",
        "                        help='the number of samples in validation dataset')\r\n",
        "    parser.add_argument('--model_ori', type=str, default='./vgg_small_model_ori.pth', \r\n",
        "                        help='the file of the original full precision vgg_small model')\r\n",
        "    parser.add_argument('--model', type=str, default='./vgg_small_model.pth', \r\n",
        "                        help='the file of the quantized vgg_small model')\r\n",
        "    parser.add_argument('--PRETRAIN', action='store_true', \r\n",
        "                        help='train the original full precision vgg_small model')\r\n",
        "    parser.add_argument('--ALQ', action='store_true',  \r\n",
        "                        help='adaptive loss-aware quantize vgg_small model')\r\n",
        "    parser.add_argument('--POSTTRAIN', action='store_true', \r\n",
        "                        help='posttrain the final quantized vgg_small model')\r\n",
        "    parser.add_argument('--lr', type=float, default=1e-3,\r\n",
        "                        help='learning rate')\r\n",
        "    parser.add_argument('--R', type=int, default=1,\r\n",
        "                        help='the number of outer iterations, also the number of pruning')\r\n",
        "    parser.add_argument('--epoch_prune', type=int, default=1,\r\n",
        "                        help='the number of epochs for pruning')\r\n",
        "    parser.add_argument('--epoch_basis', type=int, default=1,\r\n",
        "                        help='the number of epochs for optimizing bases')\r\n",
        "    parser.add_argument('--ld_basis', type=float, default=0.8,\r\n",
        "                        help='learning rate decay factor for optimizing bases')\r\n",
        "    parser.add_argument('--epoch_coord', type=int, default=1,\r\n",
        "                        help='the number of epochs for optimizing coordinates')\r\n",
        "    parser.add_argument('--ld_coord', type=float, default=0.8,\r\n",
        "                        help='learning rate decay factor for optimizing coordinates')\r\n",
        "    parser.add_argument('--wd', type=float, default=0.,\r\n",
        "                        help='weight decay')\r\n",
        "    parser.add_argument('--pr', type=float, default=0.4,\r\n",
        "                        help='the pruning ratio of alpha')\r\n",
        "    parser.add_argument('--top_k', type=float, default=0.002,\r\n",
        "                        help='the ratio of selected alpha in each layer for resorting')\r\n",
        "    parser.add_argument('--structure', type=str, nargs='+', choices=['channelwise', 'kernelwise', 'pixelwise', 'subchannelwise'], \r\n",
        "                        default=['channelwise','pixelwise','pixelwise','pixelwise','pixelwise','pixelwise','subchannelwise','subchannelwise','subchannelwise'],\r\n",
        "                        help='the structure-wise used in each layer')\r\n",
        "    parser.add_argument('--subc', type=int, nargs='+', default=[0,0,0,0,0,0,16,2,2],\r\n",
        "                        help='number of subchannels when using subchannelwise')\r\n",
        "    parser.add_argument('--max_bit', type=int, nargs='+', default=[6,6,6,6,6,6,6,6,6],\r\n",
        "                        help='the maximum bitwidth used in initialization')\r\n",
        "    parser.add_argument('--batch_size', type=int, default=128,\r\n",
        "                        help='the number of training samples in each batch')\r\n",
        "    args = parser.parse_args()\r\n",
        "    \r\n",
        "    torch.backends.cudnn.benchmark = True\r\n",
        "import torch\r\n",
        "from torchvision import datasets, transforms\r\n",
        "from torch.utils.data import DataLoader\r\n",
        "from IPython import embed\r\n",
        "import os\r\n",
        "\r\n",
        "def get(batch_size, data_root='/mnt/local0/public_dataset/pytorch/', train=True, val=True, **kwargs):\r\n",
        "    data_root = os.path.expanduser(os.path.join(data_root, 'stl10-data'))\r\n",
        "    num_workers = kwargs.setdefault('num_workers', 1)\r\n",
        "    kwargs.pop('input_size', None)\r\n",
        "    print(\"Building STL10 data loader with {} workers\".format(num_workers))\r\n",
        "    ds = []\r\n",
        "    if train:\r\n",
        "        train_loader = torch.utils.data.DataLoader(\r\n",
        "            datasets.STL10(\r\n",
        "                root=data_root, split='train', download=True,\r\n",
        "                transform=transforms.Compose([\r\n",
        "                    transforms.Pad(4),\r\n",
        "                    transforms.RandomCrop(96),\r\n",
        "                    transforms.RandomHorizontalFlip(),\r\n",
        "                    transforms.ToTensor(),\r\n",
        "                    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\r\n",
        "                ])),\r\n",
        "            batch_size=batch_size, shuffle=True, **kwargs)\r\n",
        "        ds.append(train_loader)\r\n",
        "\r\n",
        "    if val:\r\n",
        "        test_loader = torch.utils.data.DataLoader(\r\n",
        "            datasets.STL10(\r\n",
        "                root=data_root, split='test', download=True,\r\n",
        "                transform=transforms.Compose([\r\n",
        "                    transforms.ToTensor(),\r\n",
        "                    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\r\n",
        "                ])),\r\n",
        "            batch_size=batch_size, shuffle=False, **kwargs)\r\n",
        "        ds.append(test_loader)\r\n",
        "\r\n",
        "    ds = ds[0] if len(ds) == 1 else ds\r\n",
        "    return ds\r\n",
        "\r\n",
        "if __name__ == '__main__':\r\n",
        "    train_ds, test_ds = get(200, num_workers=1)\r\n",
        "    for data, target in train_ds:\r\n",
        "        print(\"~~\")\r\n",
        "\r\n",
        "\r\n",
        "    \r\n",
        "    print('pretraining...')\r\n",
        "    net = VGG_small().cuda()\r\n",
        "    loss_func = torch.nn.CrossEntropyLoss().cuda()\r\n",
        "        \r\n",
        "    optimizer = torch.optim.Adam(net.parameters(),lr=5e-2)\r\n",
        "    get_accuracy(net, train_loader, loss_func)\r\n",
        "    val_accuracy = validate(net, val_loader, loss_func)\r\n",
        "    best_acc = val_accuracy[0]\r\n",
        "    test(net, test_loader, loss_func)\r\n",
        "    save_model_ori(args.model_ori, net, optimizer)\r\n",
        "        \r\n",
        "    for epoch in range(1):\r\n",
        "            if epoch%30 == 0:\r\n",
        "                optimizer.param_groups[0]['lr'] *= 0.2\r\n",
        "            train_fullprecision(net, train_loader, loss_func, optimizer, epoch)\r\n",
        "            val_accuracy = validate(net, val_loader, loss_func)\r\n",
        "            if val_accuracy[0]>best_acc:\r\n",
        "                best_acc = val_accuracy[0]\r\n",
        "                test(net, test_loader, loss_func)\r\n",
        "                save_model_ori(args.model_ori, net, optimizer) \r\n",
        "        \r\n",
        "    # End of the for loop\r\n",
        "\r\n",
        "    \r\n",
        "    print('adaptive loss-aware quantization...')\r\n",
        "\r\n",
        "    net = VGG_small().cuda()\r\n",
        "    loss_func = torch.nn.CrossEntropyLoss().cuda() \r\n",
        "\r\n",
        "    print('loading pretrained full precision vgg_small model ...')\r\n",
        "    checkpoint = torch.load(args.model_ori)\r\n",
        "    net.load_state_dict(checkpoint['net_state_dict'])\r\n",
        "    for name, param in net.named_parameters():\r\n",
        "            print(name)\r\n",
        "            print(param.size())   \r\n",
        "\r\n",
        "    print('initialization (structured sketching)...')\r\n",
        "    parameters_w, parameters_b, parameters_w_bin = initialize(net, train_loader, loss_func, args.structure, args.subc, args.max_bit)\r\n",
        "    optimizer_b = torch.optim.Adam(parameters_b, weight_decay=args.wd) \r\n",
        "    optimizer_w = ALQ_optimizer(parameters_w, weight_decay=args.wd)\r\n",
        "    val_accuracy = validate(net, val_loader, loss_func)\r\n",
        "    best_acc = val_accuracy[0]\r\n",
        "    test(net, test_loader, loss_func)\r\n",
        "    save_model(args.model, net, optimizer_w, optimizer_b, parameters_w_bin)\r\n",
        "\r\n",
        "    M_p = (args.pr/args.top_k)/(1+args.epoch_prune*math.ceil(num_training_sample/args.batch_size))\r\n",
        "\r\n",
        "    for r in range(args.R):\r\n",
        "\r\n",
        "            print('outer iteration: ', r)\r\n",
        "            optimizer_b.param_groups[0]['lr'] = args.lr\r\n",
        "            optimizer_w.param_groups[0]['lr'] = args.lr\r\n",
        "            \r\n",
        "            print('optimizing basis...')\r\n",
        "            for q_epoch in range(args.epoch_basis):\r\n",
        "                optimizer_b.param_groups[0]['lr'] *= args.ld_basis\r\n",
        "                optimizer_w.param_groups[0]['lr'] *= args.ld_basis\r\n",
        "                train_basis(net, train_loader, loss_func, optimizer_w, optimizer_b, parameters_w_bin, q_epoch)\r\n",
        "                val_accuracy = validate(net, val_loader, loss_func)\r\n",
        "                if val_accuracy[0]>best_acc:\r\n",
        "                    best_acc = val_accuracy[0]\r\n",
        "                    test(net, test_loader, loss_func)\r\n",
        "                    #save_model(args.model, net, optimizer_w, optimizer_b, parameters_w_bin)\r\n",
        "            \r\n",
        "            print('optimizing coordinates...')\r\n",
        "            for p_epoch in range(args.epoch_coord):\r\n",
        "                optimizer_b.param_groups[0]['lr'] *= args.ld_coord\r\n",
        "                optimizer_w.param_groups[0]['lr'] *= args.ld_coord\r\n",
        "                train_coordinate(net, train_loader, loss_func, optimizer_w, optimizer_b, parameters_w_bin, p_epoch)\r\n",
        "                val_accuracy = validate(net, val_loader, loss_func)\r\n",
        "                if val_accuracy[0]>best_acc:\r\n",
        "                    best_acc = val_accuracy[0]\r\n",
        "                    test(net, test_loader, loss_func)\r\n",
        "                    #save_model(args.model, net, optimizer_w, optimizer_b, parameters_w_bin)\r\n",
        "                    \r\n",
        "            print('pruning...')\r\n",
        "            for t_epoch in range(args.epoch_prune):\r\n",
        "                prune(net, train_loader, loss_func, optimizer_w, optimizer_b, parameters_w_bin, [args.top_k, M_p], t_epoch)\r\n",
        "                val_accuracy = validate(net, val_loader, loss_func)\r\n",
        "                best_acc = val_accuracy[0]\r\n",
        "                test(net, test_loader, loss_func)\r\n",
        "                save_model(args.model, net, optimizer_w, optimizer_b, parameters_w_bin)\r\n",
        "\r\n",
        "\r\n",
        "    \r\n",
        "    print('posttraining...')\r\n",
        "            \r\n",
        "    net = VGG_small().cuda()\r\n",
        "    loss_func = torch.nn.CrossEntropyLoss().cuda()\r\n",
        "\r\n",
        "    parameters_w = []\r\n",
        "    parameters_b = []\r\n",
        "    for name, param in net.named_parameters():\r\n",
        "            if 'weight' in name and param.dim()>1:\r\n",
        "                parameters_w.append(param)\r\n",
        "            else:\r\n",
        "                parameters_b.append(param)\r\n",
        "\r\n",
        "    optimizer_b = torch.optim.Adam(parameters_b, weight_decay=args.wd) \r\n",
        "    optimizer_w = ALQ_optimizer(parameters_w, weight_decay=args.wd)\r\n",
        "        \r\n",
        "    print('load quantized vgg_small model...')\r\n",
        "    checkpoint = torch.load(args.model)\r\n",
        "    net.load_state_dict(checkpoint['net_state_dict'])\r\n",
        "    optimizer_w.load_state_dict(checkpoint['optimizer_w_state_dict'])\r\n",
        "    optimizer_b.load_state_dict(checkpoint['optimizer_b_state_dict'])\r\n",
        "    for state in optimizer_b.state.values():\r\n",
        "            for k, v in state.items():\r\n",
        "                if torch.is_tensor(v):\r\n",
        "                    state[k] = v.cuda()\r\n",
        "    for state in optimizer_w.state.values():\r\n",
        "            for k, v in state.items():\r\n",
        "                if torch.is_tensor(v):\r\n",
        "                    state[k] = v.cuda()\r\n",
        "\r\n",
        "    num_weight_layer = 0.\r\n",
        "    num_bit_layer = 0.\r\n",
        "    print('currrent binary filter number per layer: ')\r\n",
        "    for p_w_bin in parameters_w_bin:\r\n",
        "            print(p_w_bin.num_bin_filter)\r\n",
        "    print('currrent average bitwidth per layer: ')\r\n",
        "    for p_w_bin in parameters_w_bin:\r\n",
        "            num_weight_layer += p_w_bin.num_weight\r\n",
        "            num_bit_layer += p_w_bin.avg_bit*p_w_bin.num_weight\r\n",
        "            print(p_w_bin.avg_bit)\r\n",
        "    print('currrent average bitwidth: ', num_bit_layer/num_weight_layer)\r\n",
        "\r\n",
        "    get_accuracy(net, train_loader, loss_func)\r\n",
        "    val_accuracy = validate(net, val_loader, loss_func)\r\n",
        "    best_acc = val_accuracy[0]\r\n",
        "    test(net, test_loader, loss_func)\r\n",
        "    optimizer_b.param_groups[0]['lr'] = args.lr\r\n",
        "    optimizer_w.param_groups[0]['lr'] = args.lr\r\n",
        "        \r\n",
        "    print('optimizing basis with STE...')\r\n",
        "    for epoch in range(1):\r\n",
        "            optimizer_b.param_groups[0]['lr'] *= 0.95\r\n",
        "            optimizer_w.param_groups[0]['lr'] *= 0.95\r\n",
        "            train_basis_STE(net, train_loader, loss_func, optimizer_w, optimizer_b, parameters_w_bin, epoch)\r\n",
        "            val_accuracy = validate(net, val_loader, loss_func)\r\n",
        "            if val_accuracy[0]>best_acc:\r\n",
        "                best_acc = val_accuracy[0]\r\n",
        "                test(net, test_loader, loss_func)\r\n",
        "                save_model(args.model, net, optimizer_w, optimizer_b, parameters_w_bin)\r\n",
        "        \r\n",
        "    print('optimizing coordinates...')\r\n",
        "    for epoch in range(2):\r\n",
        "            optimizer_b.param_groups[0]['lr'] *= 0.9\r\n",
        "            optimizer_w.param_groups[0]['lr'] *= 0.9\r\n",
        "            train_coordinate(net, train_loader, loss_func, optimizer_w, optimizer_b, parameters_w_bin, epoch)\r\n",
        "            val_accuracy = validate(net, val_loader, loss_func)\r\n",
        "            if val_accuracy[0]>best_acc:\r\n",
        "                best_acc = val_accuracy[0]\r\n",
        "                test(net, test_loader, loss_func)\r\n",
        "                save_model(args.model, net, optimizer_w, optimizer_b, parameters_w_bin)\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Building STL10 data loader with 1 workers\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "~~\n",
            "~~\n",
            "~~\n",
            "~~\n",
            "~~\n",
            "~~\n",
            "~~\n",
            "~~\n",
            "~~\n",
            "~~\n",
            "~~\n",
            "~~\n",
            "~~\n",
            "~~\n",
            "~~\n",
            "~~\n",
            "~~\n",
            "~~\n",
            "~~\n",
            "~~\n",
            "~~\n",
            "~~\n",
            "~~\n",
            "~~\n",
            "~~\n",
            "pretraining...\n",
            "training loss:  2.302663889798251\n",
            "training accuracy:  [0.09262222222222222, 0.4994]\n",
            "validation loss:  2.302672189474106\n",
            "validation accuracy:  [0.0978, 0.5044]\n",
            "test loss:  2.302629494968849\n",
            "test accuracy:  [0.094, 0.5]\n",
            "saving...\n",
            "epoch:  0 , training loss:  1.832166663286361\n",
            "training accuracy:  [0.35486666666666666, 0.8521111111111112]\n",
            "validation loss:  1.5255082100629807\n",
            "validation accuracy:  [0.4416, 0.915]\n",
            "test loss:  1.4480182656758949\n",
            "test accuracy:  [0.4677, 0.9266]\n",
            "saving...\n",
            "adaptive loss-aware quantization...\n",
            "loading pretrained full precision vgg_small model ...\n",
            "features.0.weight\n",
            "torch.Size([128, 3, 3, 3])\n",
            "features.0.bias\n",
            "torch.Size([128])\n",
            "features.1.weight\n",
            "torch.Size([128])\n",
            "features.1.bias\n",
            "torch.Size([128])\n",
            "features.3.weight\n",
            "torch.Size([128, 128, 3, 3])\n",
            "features.3.bias\n",
            "torch.Size([128])\n",
            "features.5.weight\n",
            "torch.Size([128])\n",
            "features.5.bias\n",
            "torch.Size([128])\n",
            "features.7.weight\n",
            "torch.Size([256, 128, 3, 3])\n",
            "features.7.bias\n",
            "torch.Size([256])\n",
            "features.8.weight\n",
            "torch.Size([256])\n",
            "features.8.bias\n",
            "torch.Size([256])\n",
            "features.10.weight\n",
            "torch.Size([256, 256, 3, 3])\n",
            "features.10.bias\n",
            "torch.Size([256])\n",
            "features.12.weight\n",
            "torch.Size([256])\n",
            "features.12.bias\n",
            "torch.Size([256])\n",
            "features.14.weight\n",
            "torch.Size([512, 256, 3, 3])\n",
            "features.14.bias\n",
            "torch.Size([512])\n",
            "features.15.weight\n",
            "torch.Size([512])\n",
            "features.15.bias\n",
            "torch.Size([512])\n",
            "features.17.weight\n",
            "torch.Size([512, 512, 3, 3])\n",
            "features.17.bias\n",
            "torch.Size([512])\n",
            "features.19.weight\n",
            "torch.Size([512])\n",
            "features.19.bias\n",
            "torch.Size([512])\n",
            "classifier.0.weight\n",
            "torch.Size([1024, 8192])\n",
            "classifier.0.bias\n",
            "torch.Size([1024])\n",
            "classifier.1.weight\n",
            "torch.Size([1024])\n",
            "classifier.1.bias\n",
            "torch.Size([1024])\n",
            "classifier.3.weight\n",
            "torch.Size([1024, 1024])\n",
            "classifier.3.bias\n",
            "torch.Size([1024])\n",
            "classifier.4.weight\n",
            "torch.Size([1024])\n",
            "classifier.4.bias\n",
            "torch.Size([1024])\n",
            "classifier.6.weight\n",
            "torch.Size([10, 1024])\n",
            "classifier.6.bias\n",
            "torch.Size([10])\n",
            "initialization (structured sketching)...\n",
            "train loss:  1.567994083870541\n",
            "train accuracy:  [0.4222444444444444, 0.9048444444444445]\n",
            "currrent binary filter number per layer: \n",
            "tensor(768, device='cuda:0')\n",
            "tensor(6912, device='cuda:0')\n",
            "tensor(13824, device='cuda:0')\n",
            "tensor(13824, device='cuda:0')\n",
            "tensor(27648, device='cuda:0')\n",
            "tensor(27648, device='cuda:0')\n",
            "tensor(98304, device='cuda:0')\n",
            "tensor(12288, device='cuda:0')\n",
            "tensor(120, device='cuda:0')\n",
            "currrent average bitwidth per layer: \n",
            "tensor(6., device='cuda:0')\n",
            "tensor(6., device='cuda:0')\n",
            "tensor(6., device='cuda:0')\n",
            "tensor(6., device='cuda:0')\n",
            "tensor(6., device='cuda:0')\n",
            "tensor(6., device='cuda:0')\n",
            "tensor(6., device='cuda:0')\n",
            "tensor(6., device='cuda:0')\n",
            "tensor(6., device='cuda:0')\n",
            "currrent average bitwidth:  tensor(6., device='cuda:0')\n",
            "validation loss:  1.5826384991407394\n",
            "validation accuracy:  [0.4164, 0.9018]\n",
            "test loss:  1.4943111863317369\n",
            "test accuracy:  [0.4497, 0.9172]\n",
            "saving...\n",
            "outer iteration:  0\n",
            "optimizing basis...\n",
            "epoch:  0 , training loss:  1.2439511381089687\n",
            "training accuracy:  [0.5435111111111111, 0.9462666666666667]\n",
            "validation loss:  1.1828282862901687\n",
            "validation accuracy:  [0.563, 0.9526]\n",
            "test loss:  1.1462541033950033\n",
            "test accuracy:  [0.5834, 0.9554]\n",
            "optimizing coordinates...\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}